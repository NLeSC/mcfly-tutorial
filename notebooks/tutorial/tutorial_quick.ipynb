{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick mcfly tutorial: RacketSports dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to get you familiar with training Neural Networks for time series using mcfly. At the end of the tutorial, you will have compared several Neural Network architectures you know how to train the best performing network.\n",
    "\n",
    "Here we use a rather simple time seris dataset as an example, the publicly available [RacketSports dataset](http://www.timeseriesclassification.com/description.php?Dataset=RacketSports). It contains time series data from movement sensors form mobil phones when playing either Squash or Badminton. The data is labelled with the activity types that these individuals did and the aim is to train and evaluate a *classifier*.\n",
    "\n",
    "Before you can start, please make sure you install mcfly (see the [mcfly installation page](https://github.com/NLeSC/mcfly))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# mcfly\n",
    "import mcfly\n",
    "import tensorflow as tf\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from utils import tutorial_racketsports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data pre-procesed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a function for you to fetch the preprocessed data from https://zenodo.org/record/3743603. Please specify the `directory_to_extract_to` in the code below and then execute the cell. This will download the preprocessed data into the directory in the `RacketSports` subdirectory. The output of the function is the path where the preprocessed data was stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify in which directory you want to store the data:\n",
    "directory_to_extract_to = os.path.join('.', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "Extracting data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "data_path = tutorial_racketsports.download_preprocessed_data(directory_to_extract_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [RacketSports dataset](http://www.timeseriesclassification.com/description.php?Dataset=RacketSports) contains motion sensor data of a smart watch from people playing Squash or Badminton. It contains the senro data from gyroscope (= 3 channels) and accelerometer (= 3 channels), hence has a total of 6 channels. \n",
    "\n",
    "The problem is to identify which sport and which stroke the players are making. The data was collected at a rate of 10 HZ over 3 seconds whilst the player played either a forehand/backhand in squash or a clear/smash in badminton.\n",
    "\n",
    "\n",
    "The preprocessed data is already split into a training, a validation, and a test set.\n",
    "\n",
    "The goal of classification is to assign an activity label to an previously unseen segment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the preprocessed data as stored in Numpy-files. Please note that the data has already been split up in a training (training), validation (val), and test subsets. It is common practice to call the input data X and the labels y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = tutorial_racketsports.load_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data X and labels y are of type Numpy array. In the cell below we inspect the shape of the data. As you can see the shape of X is expressed as a Python tuple containing: the number of samples, length of the time series, and the number of channels for each sample. Similarly, the shape of y is represents the number of samples and the number of classes (unique labels). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (151, 30, 6)\n",
      "y shape: (151,)\n"
     ]
    }
   ],
   "source": [
    "print('X shape:', X_train.shape)\n",
    "print('y shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect labels (and prepare for model training)\n",
    "The labels are given as strings as provided in the original data. Those indicate one of the four possible classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Squash_BackhandBoast', 'Badminton_Smash', 'Squash_ForehandBoast', 'Badminton_Clear']\n"
     ]
    }
   ],
   "source": [
    "labels_unique = list(set(y_train))\n",
    "print(labels_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create binary labels\n",
    "To train a classifier the labels need to be translated into binary labels (so called **one-hot encoding**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Badminton_Clear', 'Badminton_Smash', 'Squash_BackhandBoast',\n",
       "       'Squash_ForehandBoast'], dtype='<U20')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(labels_unique)\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = lb.fit_transform(y_train)\n",
    "y_val_binary = lb.fit_transform(y_val)\n",
    "y_test_binary = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_binary[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split between train test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 151\n",
      "validation set size: 75\n",
      "test set size: 77\n"
     ]
    }
   ],
   "source": [
    "print('train set size:', X_train.shape[0])\n",
    "print('validation set size:', X_val.shape[0])\n",
    "print('test set size:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data \n",
    "(optional, but usually nice to get an idea of how it looks like and if everything is as expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'time points')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(np.array(X_train[10,:,:]))\n",
    "plt.xlabel('time points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 1: How many channels does this dataset have?*\n",
    "### *Question 2: What is the least common activity label in this dataset?*\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step in the development of any deep learning model is to create a model architecture. As we do not know what architecture is best for our data we will create a set of random models to investigate which architecture is most suitable for our data and classification task. This process, creating random models, checking how good they are and then selecting the best one is called a 'random search'. A random search is considered to be the most robust approach to finding a good model. You will need to specificy how many models you want to create with argument 'number_of_models'. See for a full overview of the optional arguments the function documentation of modelgen.generate_models by running `modelgen.generate_models?`.\n",
    "\n",
    "##### What number of models to select?\n",
    "This number differs per dataset. More models will give better results but it will take longer to evaluate them. Because mcfly uses random search, you will get better results when using more models. Here we will generate 8 models to keep the training short for this tutorial, but it could just as well be done for 12, or 20 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of metrics is set from ['accuracy'] (default) to ['accuracy']\n",
      "Set maximum kernel size for InceptionTime models to number of timesteps.\n"
     ]
    }
   ],
   "source": [
    "num_classes = y_train_binary.shape[1]\n",
    "metric = 'accuracy'\n",
    "models = mcfly.modelgen.generate_models(X_train.shape,\n",
    "                                        number_of_classes=num_classes,\n",
    "                                        number_of_models = 8,\n",
    "                                        metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the models\n",
    "We can have a look at the models that were generated. The layers are shown as table rows. Most common layer types are 'Convolution' and 'LSTM' and 'Dense'. For more information see the [mcfly user manual](https://github.com/NLeSC/mcfly/wiki/User-manual) and the [tutorial cheat sheet](https://github.com/NLeSC/mcfly-tutorial/blob/master/cheatsheet.md). The summary also shows the data shape of each layer output and the number of parameters that are trained within this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 0\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.005481464347736465, 'regularization_rate': 0.010209289921137055, 'network_depth': 5, 'min_filters_number': 107, 'max_kernel_size': 29}\n",
      " \n",
      "Model description:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 30, 6)        24          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 30, 107)      18725       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 30, 107)      428         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 30, 107)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 30, 107)      332128      re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 30, 107)      428         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 30, 107)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 30, 107)      332128      re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 30, 107)      428         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 30, 107)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 30, 107)      11556       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 30, 107)      0           re_lu_2[0][0]                    \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 30, 150)      321150      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 30, 150)      600         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 30, 150)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 30, 150)      450150      re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 30, 150)      600         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 30, 150)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 30, 150)      450150      re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 30, 150)      600         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 30, 150)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 30, 150)      22650       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 30, 150)      0           re_lu_5[0][0]                    \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 30, 212)      445412      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 30, 212)      848         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 30, 212)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 30, 212)      629428      re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 30, 212)      848         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 30, 212)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 30, 212)      629428      re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 30, 212)      848         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 30, 212)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 30, 212)      45156       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 30, 212)      0           re_lu_8[0][0]                    \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 30, 299)      634179      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 30, 299)      1196        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 30, 299)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 30, 299)      894309      re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 30, 299)      1196        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 30, 299)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 30, 299)      894309      re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 30, 299)      1196        conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 30, 299)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 30, 299)      89700       re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 30, 299)      0           re_lu_11[0][0]                   \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 30, 422)      883668      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 30, 422)      1688        conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 30, 422)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 30, 422)      1247010     re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 30, 422)      1688        conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 30, 422)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 30, 422)      1247010     re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 30, 422)      1688        conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 30, 422)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 30, 422)      178506      re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 30, 422)      0           re_lu_14[0][0]                   \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 422)          0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            1692        global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 9,772,748\n",
      "Trainable params: 9,765,596\n",
      "Non-trainable params: 7,152\n",
      "__________________________________________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "ResNet\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 1\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.0436664988829779, 'regularization_rate': 0.003503259200059715, 'network_depth': 3, 'filters_number': 69, 'max_kernel_size': 17}\n",
      " \n",
      "Model description:\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 30, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 30, 6)        24          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 30, 32)       192         batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 30, 6)        0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 30, 69)       37536       conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 30, 69)       17664       conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 30, 69)       8832        conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 30, 69)       414         max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30, 276)      0           conv1d_21[0][0]                  \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 30, 276)      1104        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 30, 276)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 30, 32)       8832        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 30, 276)      0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 30, 69)       37536       conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 30, 69)       17664       conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 30, 69)       8832        conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 30, 69)       19044       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 276)      0           conv1d_26[0][0]                  \n",
      "                                                                 conv1d_27[0][0]                  \n",
      "                                                                 conv1d_28[0][0]                  \n",
      "                                                                 conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 30, 276)      1104        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 30, 276)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 30, 32)       8832        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 30, 276)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 30, 69)       37536       conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 30, 69)       17664       conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 30, 69)       8832        conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 30, 69)       19044       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 30, 276)      0           conv1d_31[0][0]                  \n",
      "                                                                 conv1d_32[0][0]                  \n",
      "                                                                 conv1d_33[0][0]                  \n",
      "                                                                 conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 30, 276)      1656        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 30, 276)      1104        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 30, 276)      1104        conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 30, 276)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 30, 276)      0           batch_normalization_20[0][0]     \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 30, 276)      0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 276)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            1108        global_average_pooling1d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 255,658\n",
      "Trainable params: 253,438\n",
      "Non-trainable params: 2,220\n",
      "__________________________________________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "InceptionTime\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 2\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.0394693672382836, 'regularization_rate': 0.002879158913712458, 'filters': [48, 43, 68, 77], 'lstm_dims': [78]}\n",
      " \n",
      "Model description:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_21 (Batc (None, 30, 6)             24        \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 30, 6, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 6, 48)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 30, 6, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 6, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 6, 43)         6235      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 30, 6, 43)         172       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 6, 43)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 6, 68)         8840      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 30, 6, 68)         272       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 30, 6, 68)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 6, 77)         15785     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 30, 6, 77)         308       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 30, 6, 77)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 30, 462)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 78)            168792    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 78)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 30, 4)             316       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 4)             0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 201,128\n",
      "Trainable params: 200,644\n",
      "Non-trainable params: 484\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 3\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.012851236876927944, 'regularization_rate': 0.013689688066052806, 'filters': array([ 41,  76,  90,  62,  86,  60,  14, 100,  73,  89]), 'fc_hidden_nodes': 1595}\n",
      " \n",
      "Model description:\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_26 (Batc (None, 30, 6)             24        \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 30, 41)            779       \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 30, 41)            164       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 30, 41)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 30, 76)            9424      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 30, 76)            304       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 30, 76)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 30, 90)            20610     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 30, 90)            360       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 30, 90)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 30, 62)            16802     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 30, 62)            248       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 30, 62)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 30, 86)            16082     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 30, 86)            344       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 30, 86)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 30, 60)            15540     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 30, 60)            240       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 60)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 30, 14)            2534      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 30, 14)            56        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 30, 14)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 30, 100)           4300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 30, 100)           400       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 30, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 30, 73)            21973     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 30, 73)            292       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 30, 73)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 30, 89)            19580     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 30, 89)            356       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 30, 89)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2670)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1595)              4260245   \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 1595)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 6384      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 4,397,057\n",
      "Trainable params: 4,395,655\n",
      "Non-trainable params: 1,402\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 4\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.008923210639822017, 'regularization_rate': 0.003950367924123254, 'network_depth': 4, 'min_filters_number': 47, 'max_kernel_size': 17}\n",
      " \n",
      "Model description:\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 30, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 30, 6)        24          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 30, 47)       4841        batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 30, 47)       188         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 30, 47)       0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 30, 47)       37600       re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 30, 47)       188         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 30, 47)       0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 30, 47)       37600       re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 30, 47)       188         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 30, 47)       0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 30, 47)       2256        re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 30, 47)       0           re_lu_17[0][0]                   \n",
      "                                                                 conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 30, 66)       37290       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 30, 66)       264         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 30, 66)       0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 30, 66)       52338       re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 30, 66)       264         conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 30, 66)       0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 30, 66)       52338       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 30, 66)       264         conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 30, 66)       0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 30, 66)       4422        re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 30, 66)       0           re_lu_20[0][0]                   \n",
      "                                                                 conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 30, 93)       49197       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 30, 93)       372         conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 30, 93)       0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 30, 93)       69285       re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 30, 93)       372         conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 30, 93)       0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 30, 93)       69285       re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 30, 93)       372         conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 30, 93)       0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 30, 93)       8742        re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 30, 93)       0           re_lu_23[0][0]                   \n",
      "                                                                 conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 30, 131)      73229       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 30, 131)      524         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 30, 131)      0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 30, 131)      103097      re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 30, 131)      524         conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 30, 131)      0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 30, 131)      103097      re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 30, 131)      524         conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 30, 131)      0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 30, 131)      17292       re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 30, 131)      0           re_lu_26[0][0]                   \n",
      "                                                                 conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 131)          0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4)            528         global_average_pooling1d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 726,505\n",
      "Trainable params: 724,471\n",
      "Non-trainable params: 2,034\n",
      "__________________________________________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "ResNet\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 5\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.00041757142225341446, 'regularization_rate': 0.0010252142188453691, 'network_depth': 5, 'filters_number': 89, 'max_kernel_size': 19}\n",
      " \n",
      "Model description:\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 30, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 30, 6)        24          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 30, 32)       192         batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 30, 6)        0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 30, 89)       54112       conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 30, 89)       25632       conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 30, 89)       11392       conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 30, 89)       534         max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 30, 356)      0           conv1d_63[0][0]                  \n",
      "                                                                 conv1d_64[0][0]                  \n",
      "                                                                 conv1d_65[0][0]                  \n",
      "                                                                 conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 30, 356)      1424        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 30, 356)      0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 30, 32)       11392       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 30, 356)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 30, 89)       54112       conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 30, 89)       25632       conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 30, 89)       11392       conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 30, 89)       31684       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 30, 356)      0           conv1d_68[0][0]                  \n",
      "                                                                 conv1d_69[0][0]                  \n",
      "                                                                 conv1d_70[0][0]                  \n",
      "                                                                 conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 30, 356)      1424        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 30, 356)      0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 30, 32)       11392       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 30, 356)      0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 30, 89)       54112       conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 30, 89)       25632       conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 30, 89)       11392       conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 30, 89)       31684       max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 30, 356)      0           conv1d_73[0][0]                  \n",
      "                                                                 conv1d_74[0][0]                  \n",
      "                                                                 conv1d_75[0][0]                  \n",
      "                                                                 conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 30, 356)      2136        batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 30, 356)      1424        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 30, 356)      1424        conv1d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 30, 356)      0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 30, 356)      0           batch_normalization_55[0][0]     \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 30, 356)      0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 30, 32)       11392       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 30, 356)      0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 30, 89)       54112       conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 30, 89)       25632       conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 30, 89)       11392       conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 30, 89)       31684       max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 30, 356)      0           conv1d_79[0][0]                  \n",
      "                                                                 conv1d_80[0][0]                  \n",
      "                                                                 conv1d_81[0][0]                  \n",
      "                                                                 conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 30, 356)      1424        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 30, 356)      0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 30, 32)       11392       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 30, 356)      0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, 30, 89)       54112       conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 30, 89)       25632       conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 30, 89)       11392       conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, 30, 89)       31684       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 30, 356)      0           conv1d_84[0][0]                  \n",
      "                                                                 conv1d_85[0][0]                  \n",
      "                                                                 conv1d_86[0][0]                  \n",
      "                                                                 conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 30, 356)      1424        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 30, 356)      0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 356)          0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            1428        global_average_pooling1d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 640,842\n",
      "Trainable params: 636,558\n",
      "Non-trainable params: 4,284\n",
      "__________________________________________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "InceptionTime\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 6\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.0007902107985188801, 'regularization_rate': 0.00012774583804330792, 'filters': array([53, 42, 36, 18]), 'fc_hidden_nodes': 1622}\n",
      " \n",
      "Model description:\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_58 (Batc (None, 30, 6)             24        \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 30, 53)            1007      \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 30, 53)            212       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 30, 53)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 30, 42)            6720      \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 30, 42)            168       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 30, 42)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 30, 36)            4572      \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 30, 36)            144       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 30, 36)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 30, 18)            1962      \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 30, 18)            72        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 30, 18)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 540)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1622)              877502    \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1622)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 6492      \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 898,891\n",
      "Trainable params: 898,573\n",
      "Non-trainable params: 318\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 7\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.005216294589208116, 'regularization_rate': 0.004895062158334504, 'filters': [80, 96, 80, 29, 66, 92, 11, 78, 50, 91], 'lstm_dims': [28, 94]}\n",
      " \n",
      "Model description:\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_64 (Batc (None, 30, 6)             24        \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 30, 6, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 6, 80)         320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 30, 6, 80)         320       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 30, 6, 80)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 6, 96)         23136     \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 30, 6, 96)         384       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 30, 6, 96)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 6, 80)         23120     \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 30, 6, 80)         320       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 30, 6, 80)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 6, 29)         6989      \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 30, 6, 29)         116       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 30, 6, 29)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 6, 66)         5808      \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 30, 6, 66)         264       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 30, 6, 66)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 6, 92)         18308     \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 30, 6, 92)         368       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 30, 6, 92)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 6, 11)         3047      \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 30, 6, 11)         44        \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 30, 6, 11)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 6, 78)         2652      \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 30, 6, 78)         312       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 30, 6, 78)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 6, 50)         11750     \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 30, 6, 50)         200       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 30, 6, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 6, 91)         13741     \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 30, 6, 91)         364       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 30, 6, 91)         0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 30, 546)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 28)            64400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 94)            46248     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 94)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 4)             380       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 30, 4)             0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 222,615\n",
      "Trainable params: 221,257\n",
      "Non-trainable params: 1,358\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n"
     ]
    }
   ],
   "source": [
    "models_to_print = range(len(models))\n",
    "for i, item in enumerate(models):\n",
    "    if i in models_to_print:\n",
    "        model, params, model_types = item\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"Model \" + str(i))\n",
    "        print(\" \")\n",
    "        print(\"Hyperparameters:\")\n",
    "        print(params)\n",
    "        print(\" \")\n",
    "        print(\"Model description:\")\n",
    "        model.summary()\n",
    "        print(\" \")\n",
    "        print(\"Model type:\")\n",
    "        print(model_types)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a very quick view we can also just look the list of created models itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tensorflow.python.keras.engine.training.Model at 0x1d92bad0908>,\n",
       "  {'learning_rate': 0.005481464347736465,\n",
       "   'regularization_rate': 0.010209289921137055,\n",
       "   'network_depth': 5,\n",
       "   'min_filters_number': 107,\n",
       "   'max_kernel_size': 29},\n",
       "  'ResNet'),\n",
       " (<tensorflow.python.keras.engine.training.Model at 0x1d92bd56e88>,\n",
       "  {'learning_rate': 0.0436664988829779,\n",
       "   'regularization_rate': 0.003503259200059715,\n",
       "   'network_depth': 3,\n",
       "   'filters_number': 69,\n",
       "   'max_kernel_size': 17},\n",
       "  'InceptionTime'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x1d92bd56308>,\n",
       "  {'learning_rate': 0.0394693672382836,\n",
       "   'regularization_rate': 0.002879158913712458,\n",
       "   'filters': [48, 43, 68, 77],\n",
       "   'lstm_dims': [78]},\n",
       "  'DeepConvLSTM'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x1d92c35a188>,\n",
       "  {'learning_rate': 0.012851236876927944,\n",
       "   'regularization_rate': 0.013689688066052806,\n",
       "   'filters': array([ 41,  76,  90,  62,  86,  60,  14, 100,  73,  89]),\n",
       "   'fc_hidden_nodes': 1595},\n",
       "  'CNN'),\n",
       " (<tensorflow.python.keras.engine.training.Model at 0x1d92dba3ec8>,\n",
       "  {'learning_rate': 0.008923210639822017,\n",
       "   'regularization_rate': 0.003950367924123254,\n",
       "   'network_depth': 4,\n",
       "   'min_filters_number': 47,\n",
       "   'max_kernel_size': 17},\n",
       "  'ResNet'),\n",
       " (<tensorflow.python.keras.engine.training.Model at 0x1d92ee87d48>,\n",
       "  {'learning_rate': 0.00041757142225341446,\n",
       "   'regularization_rate': 0.0010252142188453691,\n",
       "   'network_depth': 5,\n",
       "   'filters_number': 89,\n",
       "   'max_kernel_size': 19},\n",
       "  'InceptionTime'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x1d92ee86848>,\n",
       "  {'learning_rate': 0.0007902107985188801,\n",
       "   'regularization_rate': 0.00012774583804330792,\n",
       "   'filters': array([53, 42, 36, 18]),\n",
       "   'fc_hidden_nodes': 1622},\n",
       "  'CNN'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x1d92f063ec8>,\n",
       "  {'learning_rate': 0.005216294589208116,\n",
       "   'regularization_rate': 0.004895062158334504,\n",
       "   'filters': [80, 96, 80, 29, 66, 92, 11, 78, 50, 91],\n",
       "   'lstm_dims': [28, 94]},\n",
       "  'DeepConvLSTM')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 3: Can you guess what hyperparameter 'learning rate' stands for?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare models\n",
    "Now that the model architectures have been generated it is time to compare the models by training them on a subset of the training data and evaluating the models on the validation subset. This will help us to choose the best candidate model. The performance results for the models are stored in a json file, which we will visually inspect later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory where the results, e.g. json file, will be stored\n",
    "resultpath = os.path.join(directory_to_extract_to, 'models')\n",
    "if not os.path.exists(resultpath):\n",
    "    os.makedirs(resultpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models\n",
    "We are now going to train each of the models that we generated. On the one hand we want to train them as quickly as possible in order to be able to pick the best one as soon as possible. On the other hand we have to train each model long enough to get a good impression of its potential. As default mcfly uses **early stopping** which means that it will stop the training once the models accuracy on the validation set decreases. To better account for usually occuring fluctuations in the accuracy, we here set **early_stopping_patience = 5** which means that the model will stop if the validation accuracy has not improved since 5 epochs.\n",
    "\n",
    "We can influence the train time by adjusting the number of data samples that are used. This can be set with the argument 'subset_size'. We can also adjust the number of times the subset is iterated over. This number is called an epoch. For more complex dataset we recommend to start with no more than 5 epochs and a maximum subset size of 300. You can experiment with these numbers.\n",
    "\n",
    "Here, however, we work with a very small dataset (in terms of time resolution, channels, and number of samples). So we can run at longer training already.\n",
    "\n",
    "### The following training will take several minutes to run.\n",
    "This depends on the model architectures that were generated, the data used, and -obviously- the hardware this code is run on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated models will be trained on subset of the data (subset size: 300).\n",
      "Training model 0 ResNet\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 19s 129ms/sample - loss: 5.5956 - accuracy: 0.2318 - val_loss: 907247921834.6665 - val_accuracy: 0.2667\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 9s 59ms/sample - loss: 3.1922 - accuracy: 0.2583 - val_loss: 18883982950.4000 - val_accuracy: 0.2667\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 9s 59ms/sample - loss: 2.2119 - accuracy: 0.4172 - val_loss: 510153344.0000 - val_accuracy: 0.2667\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 9s 59ms/sample - loss: 1.2904 - accuracy: 0.4371 - val_loss: 30527423.2667 - val_accuracy: 0.2800\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 9s 60ms/sample - loss: 1.2798 - accuracy: 0.3907 - val_loss: 2673339.9500 - val_accuracy: 0.2800\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 9s 59ms/sample - loss: 1.4474 - accuracy: 0.3444 - val_loss: 473958.9292 - val_accuracy: 0.2800\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 9s 60ms/sample - loss: 1.8912 - accuracy: 0.4834 - val_loss: 260538.0125 - val_accuracy: 0.2667\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 10s 63ms/sample - loss: 1.8870 - accuracy: 0.3907 - val_loss: 62244.9417 - val_accuracy: 0.2667\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 10s 65ms/sample - loss: 1.2276 - accuracy: 0.4238 - val_loss: 10034.3166 - val_accuracy: 0.2800\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 9s 62ms/sample - loss: 1.2756 - accuracy: 0.3642 - val_loss: 6880.5100 - val_accuracy: 0.2667\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 9s 62ms/sample - loss: 1.1647 - accuracy: 0.4371 - val_loss: 1677.0653 - val_accuracy: 0.3067\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 10s 64ms/sample - loss: 1.2284 - accuracy: 0.3377 - val_loss: 733.1457 - val_accuracy: 0.2533\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 9s 59ms/sample - loss: 1.1206 - accuracy: 0.4238 - val_loss: 164.0171 - val_accuracy: 0.2667\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 9s 62ms/sample - loss: 1.1467 - accuracy: 0.3841 - val_loss: 38.2676 - val_accuracy: 0.2533\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 10s 64ms/sample - loss: 1.1079 - accuracy: 0.3775 - val_loss: 17.2900 - val_accuracy: 0.2933\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 9s 60ms/sample - loss: 1.0301 - accuracy: 0.4636 - val_loss: 11.5363 - val_accuracy: 0.2533\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 9s 62ms/sample - loss: 0.8694 - accuracy: 0.4305 - val_loss: 10.4104 - val_accuracy: 0.3067\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 9s 58ms/sample - loss: 1.1992 - accuracy: 0.3841 - val_loss: 6.4564 - val_accuracy: 0.2933\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 9s 61ms/sample - loss: 1.1099 - accuracy: 0.4305 - val_loss: 11.2903 - val_accuracy: 0.2800\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 9s 61ms/sample - loss: 1.0908 - accuracy: 0.4503 - val_loss: 10.4869 - val_accuracy: 0.2533\n",
      "Training model 1 InceptionTime\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 5s 32ms/sample - loss: 2.5156 - accuracy: 0.4106 - val_loss: 1945.9055 - val_accuracy: 0.2667\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.7346 - accuracy: 0.6358 - val_loss: 755.9216 - val_accuracy: 0.3067\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.4771 - accuracy: 0.7881 - val_loss: 489.6784 - val_accuracy: 0.2667\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.4679 - accuracy: 0.7815 - val_loss: 128.5871 - val_accuracy: 0.4267\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.2872 - accuracy: 0.9007 - val_loss: 174.6595 - val_accuracy: 0.2667\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.2553 - accuracy: 0.8874 - val_loss: 100.8528 - val_accuracy: 0.2667\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 1s 8ms/sample - loss: 0.1812 - accuracy: 0.9073 - val_loss: 56.5696 - val_accuracy: 0.2933\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 1s 8ms/sample - loss: 0.3470 - accuracy: 0.8411 - val_loss: 45.4224 - val_accuracy: 0.2800\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.2734 - accuracy: 0.9073 - val_loss: 33.5496 - val_accuracy: 0.4533\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.1539 - accuracy: 0.9272 - val_loss: 47.2048 - val_accuracy: 0.4667\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.1875 - accuracy: 0.9404 - val_loss: 62.2394 - val_accuracy: 0.3200\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.2292 - accuracy: 0.9205 - val_loss: 27.7040 - val_accuracy: 0.4533\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.2323 - accuracy: 0.8940 - val_loss: 21.8928 - val_accuracy: 0.4000\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.1266 - accuracy: 0.9669 - val_loss: 37.1494 - val_accuracy: 0.2800\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.1066 - accuracy: 0.9669 - val_loss: 25.2455 - val_accuracy: 0.3600\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.0644 - accuracy: 0.9669 - val_loss: 16.7765 - val_accuracy: 0.4000\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.0795 - accuracy: 0.9669 - val_loss: 24.6196 - val_accuracy: 0.4000\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.1682 - accuracy: 0.9669 - val_loss: 12.3581 - val_accuracy: 0.4667\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.1188 - accuracy: 0.9603 - val_loss: 15.8911 - val_accuracy: 0.4933\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 1s 8ms/sample - loss: 0.0695 - accuracy: 0.9801 - val_loss: 30.0673 - val_accuracy: 0.3600\n",
      "Training model 2 DeepConvLSTM\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 7s 47ms/sample - loss: 2.8400 - accuracy: 0.2450 - val_loss: 2.6562 - val_accuracy: 0.2800\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 1s 8ms/sample - loss: 2.6497 - accuracy: 0.2649 - val_loss: 2.1984 - val_accuracy: 0.2667\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 2.0777 - accuracy: 0.2384 - val_loss: 1.7731 - val_accuracy: 0.2267\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 1.8138 - accuracy: 0.2119 - val_loss: 1.6664 - val_accuracy: 0.2667\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 1.7422 - accuracy: 0.2517 - val_loss: 1.6812 - val_accuracy: 0.2800\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 1.6469 - accuracy: 0.3046 - val_loss: 1.5403 - val_accuracy: 0.2667\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 1.5891 - accuracy: 0.2715 - val_loss: 1.4470 - val_accuracy: 0.2667\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 1.5631 - accuracy: 0.2252 - val_loss: 1.5143 - val_accuracy: 0.2800\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 1.5842 - accuracy: 0.2583 - val_loss: 1.4959 - val_accuracy: 0.2800\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 1s 8ms/sample - loss: 1.4998 - accuracy: 0.2914 - val_loss: 1.4945 - val_accuracy: 0.2667\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 1.5960 - accuracy: 0.2318 - val_loss: 1.5329 - val_accuracy: 0.2800\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 1s 8ms/sample - loss: 1.6218 - accuracy: 0.2053 - val_loss: 1.4923 - val_accuracy: 0.2267\n",
      "Epoch 00012: early stopping\n",
      "Training model 3 CNN\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 8s 56ms/sample - loss: 43.0588 - accuracy: 0.5033 - val_loss: 2043.8872 - val_accuracy: 0.2800\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 1s 6ms/sample - loss: 32.4847 - accuracy: 0.6954 - val_loss: 500.9733 - val_accuracy: 0.2667\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 16.6480 - accuracy: 0.7815 - val_loss: 39.5635 - val_accuracy: 0.3333\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 9.8855 - accuracy: 0.8146 - val_loss: 13.1508 - val_accuracy: 0.2400\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 6.5098 - accuracy: 0.7881 - val_loss: 5.9794 - val_accuracy: 0.3333\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 5.3668 - accuracy: 0.7020 - val_loss: 4.9859 - val_accuracy: 0.5467\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 4.0921 - accuracy: 0.7417 - val_loss: 4.7857 - val_accuracy: 0.2800\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 3.6269 - accuracy: 0.7483 - val_loss: 4.8893 - val_accuracy: 0.4667\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 2.6853 - accuracy: 0.7616 - val_loss: 3.0438 - val_accuracy: 0.4133\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 2.5996 - accuracy: 0.7417 - val_loss: 3.4150 - val_accuracy: 0.3200\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 2.2283 - accuracy: 0.7748 - val_loss: 2.7893 - val_accuracy: 0.5333\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 2.2000 - accuracy: 0.7815 - val_loss: 3.2605 - val_accuracy: 0.3733\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 1.8044 - accuracy: 0.8477 - val_loss: 2.6838 - val_accuracy: 0.3867\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 1.6385 - accuracy: 0.8742 - val_loss: 2.9837 - val_accuracy: 0.2267\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 2.2341 - accuracy: 0.8278 - val_loss: 11.3417 - val_accuracy: 0.2267\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 1.6408 - accuracy: 0.8212 - val_loss: 2.6633 - val_accuracy: 0.4133\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 1.3488 - accuracy: 0.8874 - val_loss: 2.4574 - val_accuracy: 0.2267\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 1.2550 - accuracy: 0.9139 - val_loss: 2.2977 - val_accuracy: 0.2267\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 1.4662 - accuracy: 0.8609 - val_loss: 2.6798 - val_accuracy: 0.3200\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 1.3611 - accuracy: 0.8411 - val_loss: 3.3044 - val_accuracy: 0.2267\n",
      "Training model 4 ResNet\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 9s 63ms/sample - loss: 1.9250 - accuracy: 0.2517 - val_loss: 820787.2500 - val_accuracy: 0.2800\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 2s 11ms/sample - loss: 1.2573 - accuracy: 0.5563 - val_loss: 1702234.1833 - val_accuracy: 0.2667\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 2s 10ms/sample - loss: 0.7227 - accuracy: 0.6291 - val_loss: 819102.5083 - val_accuracy: 0.2267\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 2s 10ms/sample - loss: 0.6381 - accuracy: 0.7020 - val_loss: 21085.0617 - val_accuracy: 0.3867\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 2s 11ms/sample - loss: 0.5617 - accuracy: 0.6954 - val_loss: 3203.6953 - val_accuracy: 0.2933\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 2s 11ms/sample - loss: 0.5883 - accuracy: 0.6954 - val_loss: 1811.2066 - val_accuracy: 0.4133\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 2s 11ms/sample - loss: 0.6195 - accuracy: 0.7020 - val_loss: 2705.3856 - val_accuracy: 0.4667\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 1s 10ms/sample - loss: 0.5456 - accuracy: 0.7616 - val_loss: 1708.8102 - val_accuracy: 0.4533\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 2s 11ms/sample - loss: 0.5040 - accuracy: 0.7947 - val_loss: 143.8305 - val_accuracy: 0.5067\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 2s 11ms/sample - loss: 0.6606 - accuracy: 0.7020 - val_loss: 169.0168 - val_accuracy: 0.4667\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 2s 11ms/sample - loss: 0.4373 - accuracy: 0.7748 - val_loss: 249.1598 - val_accuracy: 0.4667\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 2s 11ms/sample - loss: 0.2691 - accuracy: 0.8874 - val_loss: 188.2021 - val_accuracy: 0.4800\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 2s 11ms/sample - loss: 0.1714 - accuracy: 0.9338 - val_loss: 122.3095 - val_accuracy: 0.5067\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 2s 11ms/sample - loss: 0.2083 - accuracy: 0.9338 - val_loss: 444.7937 - val_accuracy: 0.4400\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 2s 10ms/sample - loss: 0.2729 - accuracy: 0.9139 - val_loss: 148.1323 - val_accuracy: 0.4267\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 2s 10ms/sample - loss: 0.6049 - accuracy: 0.8940 - val_loss: 153.6151 - val_accuracy: 0.4267\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 1s 10ms/sample - loss: 0.9965 - accuracy: 0.7351 - val_loss: 146.1706 - val_accuracy: 0.4400\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 1s 10ms/sample - loss: 0.4637 - accuracy: 0.8477 - val_loss: 89.6011 - val_accuracy: 0.7067\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 2s 10ms/sample - loss: 0.4582 - accuracy: 0.8543 - val_loss: 191.9169 - val_accuracy: 0.5733\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 2s 11ms/sample - loss: 0.2078 - accuracy: 0.9139 - val_loss: 224.2076 - val_accuracy: 0.6533\n",
      "Training model 5 InceptionTime\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 10s 64ms/sample - loss: 1.0996 - accuracy: 0.5298 - val_loss: 2.3040 - val_accuracy: 0.3467\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.3443 - accuracy: 0.9205 - val_loss: 2.4449 - val_accuracy: 0.4667\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.1381 - accuracy: 0.9603 - val_loss: 1.9947 - val_accuracy: 0.5067\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0825 - accuracy: 0.9801 - val_loss: 1.5277 - val_accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0413 - accuracy: 1.0000 - val_loss: 1.4832 - val_accuracy: 0.6000\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0228 - accuracy: 0.9934 - val_loss: 2.3606 - val_accuracy: 0.5600\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.7082 - val_accuracy: 0.6133\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.7589 - val_accuracy: 0.7067\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6266 - val_accuracy: 0.7333\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9395 - val_accuracy: 0.7467\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0100 - accuracy: 0.9934 - val_loss: 0.5867 - val_accuracy: 0.8133\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.7867\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.8533\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 2s 14ms/sample - loss: 0.0161 - accuracy: 0.9934 - val_loss: 0.3093 - val_accuracy: 0.8933\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.8533\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.8667\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.8400\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.8400\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 3s 17ms/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9067\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9067\n",
      "Training model 6 CNN\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 5s 30ms/sample - loss: 1.3089 - accuracy: 0.5497 - val_loss: 1.9083 - val_accuracy: 0.4133\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.7766 - accuracy: 0.9073 - val_loss: 1.7572 - val_accuracy: 0.4667\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.6737 - accuracy: 0.9735 - val_loss: 1.4720 - val_accuracy: 0.4800\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.6201 - accuracy: 0.9669 - val_loss: 1.3201 - val_accuracy: 0.5200\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.5829 - accuracy: 0.9868 - val_loss: 1.2285 - val_accuracy: 0.6000\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.5659 - accuracy: 0.9934 - val_loss: 1.1688 - val_accuracy: 0.6800\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.5795 - accuracy: 0.9934 - val_loss: 1.1463 - val_accuracy: 0.7200\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.5452 - accuracy: 1.0000 - val_loss: 1.1420 - val_accuracy: 0.7467\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.5003 - accuracy: 1.0000 - val_loss: 1.1378 - val_accuracy: 0.7333\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.5022 - accuracy: 1.0000 - val_loss: 1.1293 - val_accuracy: 0.7467\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.5139 - accuracy: 1.0000 - val_loss: 1.1282 - val_accuracy: 0.7333\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.5269 - accuracy: 0.9934 - val_loss: 1.1183 - val_accuracy: 0.7200\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.5027 - accuracy: 1.0000 - val_loss: 1.0951 - val_accuracy: 0.7600\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.4922 - accuracy: 0.9934 - val_loss: 1.0800 - val_accuracy: 0.7733\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.4667 - accuracy: 1.0000 - val_loss: 1.0691 - val_accuracy: 0.7600\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.4647 - accuracy: 1.0000 - val_loss: 1.0615 - val_accuracy: 0.7600\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.4955 - accuracy: 1.0000 - val_loss: 1.0590 - val_accuracy: 0.7467\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.4900 - accuracy: 0.9934 - val_loss: 1.0563 - val_accuracy: 0.7467\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.4766 - accuracy: 1.0000 - val_loss: 1.0533 - val_accuracy: 0.7600\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 0.4783 - accuracy: 0.9934 - val_loss: 1.0374 - val_accuracy: 0.7600\n",
      "Training model 7 DeepConvLSTM\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 14s 92ms/sample - loss: 4.3401 - accuracy: 0.2715 - val_loss: 3.7400 - val_accuracy: 0.2800\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 3s 18ms/sample - loss: 3.1242 - accuracy: 0.4106 - val_loss: 3.2421 - val_accuracy: 0.2933\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 3s 18ms/sample - loss: 2.4274 - accuracy: 0.4437 - val_loss: 2.6420 - val_accuracy: 0.2800\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 3s 18ms/sample - loss: 2.0500 - accuracy: 0.4967 - val_loss: 2.8530 - val_accuracy: 0.2800\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 3s 18ms/sample - loss: 1.8234 - accuracy: 0.4768 - val_loss: 2.0451 - val_accuracy: 0.4133\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 3s 18ms/sample - loss: 1.6340 - accuracy: 0.5762 - val_loss: 2.4483 - val_accuracy: 0.3600\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 3s 17ms/sample - loss: 1.6208 - accuracy: 0.5762 - val_loss: 2.3428 - val_accuracy: 0.3467\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 3s 18ms/sample - loss: 1.5286 - accuracy: 0.6291 - val_loss: 2.0021 - val_accuracy: 0.3467\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 3s 17ms/sample - loss: 1.3230 - accuracy: 0.7417 - val_loss: 2.6441 - val_accuracy: 0.3467\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 3s 17ms/sample - loss: 1.1980 - accuracy: 0.6887 - val_loss: 1.5608 - val_accuracy: 0.5600\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 3s 17ms/sample - loss: 1.3663 - accuracy: 0.6026 - val_loss: 1.7343 - val_accuracy: 0.4267\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 3s 18ms/sample - loss: 1.1050 - accuracy: 0.6821 - val_loss: 1.3953 - val_accuracy: 0.6400\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 3s 18ms/sample - loss: 1.0122 - accuracy: 0.7550 - val_loss: 1.0993 - val_accuracy: 0.7600\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 3s 18ms/sample - loss: 1.0465 - accuracy: 0.7020 - val_loss: 0.8656 - val_accuracy: 0.7867\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 3s 18ms/sample - loss: 0.9620 - accuracy: 0.7483 - val_loss: 1.1375 - val_accuracy: 0.7333\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 3s 18ms/sample - loss: 1.0363 - accuracy: 0.7086 - val_loss: 1.4553 - val_accuracy: 0.5200\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 3s 18ms/sample - loss: 0.8862 - accuracy: 0.8079 - val_loss: 1.0696 - val_accuracy: 0.6400\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 3s 21ms/sample - loss: 0.9683 - accuracy: 0.7616 - val_loss: 1.1078 - val_accuracy: 0.7333\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 3s 20ms/sample - loss: 0.8091 - accuracy: 0.8278 - val_loss: 0.8358 - val_accuracy: 0.7600\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 3s 20ms/sample - loss: 0.7589 - accuracy: 0.8278 - val_loss: 1.3030 - val_accuracy: 0.6400\n",
      "Details of the training process were stored in  .\\data\\models\\modelcomparison.json\n"
     ]
    }
   ],
   "source": [
    "from mcfly.find_architecture import train_models_on_samples\n",
    "\n",
    "outputfile = os.path.join(resultpath, 'modelcomparison.json')\n",
    "histories, val_accuracies, val_losses = train_models_on_samples(X_train, y_train_binary,\n",
    "                                                                X_val, y_val_binary,\n",
    "                                                                models, nr_epochs=20,\n",
    "                                                                subset_size=300,\n",
    "                                                                early_stopping_patience = 5,\n",
    "                                                                verbose=True,\n",
    "                                                                outputfile=outputfile,\n",
    "                                                                metric=metric)\n",
    "print('Details of the training process were stored in ',outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4: What do the terms 'acc' and 'loss' in the output refer to?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect model performance (Visualization)\n",
    "\n",
    "We can inspect the learning process in the visualization tool on http://nlesc.github.io/mcfly/.\n",
    "\n",
    "Alternatively, you can run the visualization from a local web service:\n",
    "- Clone the mcfly github repository (if you haven't done so already for visualization)\n",
    "\n",
    " `git clone https://github.com/NLeSC/mcfly`\n",
    "\n",
    "\n",
    "- navigate to the html folder:\n",
    "\n",
    " `cd mcfly/html`\n",
    "\n",
    "\n",
    "- Start a web server. This can be done in various ways, for example:\n",
    "`python3 -m http.server`\n",
    "\n",
    "Notice the port number the web server is serving on. This is usually 8000.\n",
    "With a web browser, navigate to [localhost:8000](localhost:8000). \n",
    "\n",
    "You need to upload the json file that contains the details of the training process. The following line of code shows the path to this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\data\\\\models\\\\modelcomparison.json'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 5:  Look at the visualization. Which model performs best?*\n",
    "### *Question 6:  Did you train all models with a sufficient number of iterations?*\n",
    "### *Question 7:  Are there cases of clear overfitting?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect model performance (table)\n",
    "\n",
    "Let's compare the performance of the models by showing the results as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model-type</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.005481464347736465, 'regul...</td>\n",
       "      <td>ResNet</td>\n",
       "      <td>0.450331</td>\n",
       "      <td>1.090753</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>10.486857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.0436664988829779, 'regular...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>0.980132</td>\n",
       "      <td>0.069513</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>30.067336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.0394693672382836, 'regular...</td>\n",
       "      <td>DeepConvLSTM</td>\n",
       "      <td>0.205298</td>\n",
       "      <td>1.621776</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>1.492279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.012851236876927944, 'regul...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>1.361104</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>3.304446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.008923210639822017, 'regul...</td>\n",
       "      <td>ResNet</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.207766</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>224.207554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 0.00041757142225341446, 'reg...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.347267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'learning_rate': 0.0007902107985188801, 'regu...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.993378</td>\n",
       "      <td>0.478264</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.037439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'learning_rate': 0.005216294589208116, 'regul...</td>\n",
       "      <td>DeepConvLSTM</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.758923</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>1.303036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model     model-type  \\\n",
       "0  {'learning_rate': 0.005481464347736465, 'regul...         ResNet   \n",
       "1  {'learning_rate': 0.0436664988829779, 'regular...  InceptionTime   \n",
       "2  {'learning_rate': 0.0394693672382836, 'regular...   DeepConvLSTM   \n",
       "3  {'learning_rate': 0.012851236876927944, 'regul...            CNN   \n",
       "4  {'learning_rate': 0.008923210639822017, 'regul...         ResNet   \n",
       "5  {'learning_rate': 0.00041757142225341446, 'reg...  InceptionTime   \n",
       "6  {'learning_rate': 0.0007902107985188801, 'regu...            CNN   \n",
       "7  {'learning_rate': 0.005216294589208116, 'regul...   DeepConvLSTM   \n",
       "\n",
       "   train_accuracy  train_loss  val_accuracy    val_loss  \n",
       "0        0.450331    1.090753      0.253333   10.486857  \n",
       "1        0.980132    0.069513      0.360000   30.067336  \n",
       "2        0.205298    1.621776      0.226667    1.492279  \n",
       "3        0.841060    1.361104      0.226667    3.304446  \n",
       "4        0.913907    0.207766      0.653333  224.207554  \n",
       "5        1.000000    0.005901      0.906667    0.347267  \n",
       "6        0.993378    0.478264      0.760000    1.037439  \n",
       "7        0.827815    0.758923      0.640000    1.303036  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = 'accuracy'\n",
    "modelcomparisons = pd.DataFrame({'model':[str(params) for model, params, model_types in models],\n",
    "                                'model-type':[str(model_types) for model, params, model_types in models],\n",
    "                                'train_{}'.format(metric): [history.history[metric][-1] for history in histories],\n",
    "                                'train_loss': [history.history['loss'][-1] for history in histories],\n",
    "                                'val_{}'.format(metric): [history.history['val_{}'.format(metric)][-1] for history in histories],\n",
    "                                'val_loss': [history.history['val_loss'][-1] for history in histories]\n",
    "                                })\n",
    "modelcomparisons.to_csv(os.path.join(resultpath, 'modelcomparisons.csv'))\n",
    "\n",
    "modelcomparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps:\n",
    "## 1) Continue iteratively: generate more models of desired type\n",
    "*mcfly* is generating models of 4 different architecture types (CNN, DeepConvLSTM, ResNet, InceptionTime). There performance of course strongly depends on the hyperparameters used, but they also all have different strengths and weaknesses. Often it makes sense to select the most promising type(s) after the first screening we did above and continue to explore options further.\n",
    "\n",
    "### Narrow the search: model types\n",
    "In this case, let's say that the most promising models were of typ CNN and InceptionTime. So we will ignore the other architecture for now.\n",
    "We can do this in *mcfly* by specifing which models we want to generate: ``model_types = ['CNN', 'InceptionTime']``\n",
    "\n",
    "### Narrow the search: hyperparameters\n",
    "Figuring out which hyperparameters work better than others can be very complicated since often there exist complex links between them. But let's say we already figured something out, e.g. that high learning rates lead to overfitting on our data. Then *mcfly* easily allows to restrict the parameter search space!\n",
    "Simply add the new desired range to the generate_models function: ``low_lr=2``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of model_types is set from ['CNN', 'DeepConvLSTM', 'ResNet', 'InceptionTime'] (default) to ['CNN', 'InceptionTime']\n",
      "The value of low_lr is set from 1 (default) to 2\n",
      "The value of metrics is set from ['accuracy'] (default) to ['accuracy']\n",
      "Set maximum kernel size for InceptionTime models to number of timesteps.\n"
     ]
    }
   ],
   "source": [
    "num_classes = y_train_binary.shape[1]\n",
    "metric = 'accuracy'\n",
    "models = mcfly.modelgen.generate_models(X_train.shape,\n",
    "                                        number_of_classes=num_classes,\n",
    "                                        number_of_models = 8,\n",
    "                                        model_types = ['CNN', 'InceptionTime'],\n",
    "                                        low_lr=2,\n",
    "                                        metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again now have to train those newly generated models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated models will be trained on subset of the data (subset size: 300).\n",
      "Training model 0 InceptionTime\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 7s 44ms/sample - loss: 1.1319 - accuracy: 0.5762 - val_loss: 2.0306 - val_accuracy: 0.2667\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 0.6355 - accuracy: 0.8609 - val_loss: 2.6487 - val_accuracy: 0.2667\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 0.4208 - accuracy: 0.9007 - val_loss: 1.8872 - val_accuracy: 0.3067\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.2631 - accuracy: 0.9470 - val_loss: 1.5133 - val_accuracy: 0.4133\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.1977 - accuracy: 0.9735 - val_loss: 1.1984 - val_accuracy: 0.6267\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.1306 - accuracy: 0.9868 - val_loss: 1.2518 - val_accuracy: 0.6267\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 0.0877 - accuracy: 0.9934 - val_loss: 0.8640 - val_accuracy: 0.6800\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.8586 - val_accuracy: 0.6800\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.8258 - val_accuracy: 0.7067\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.6251 - val_accuracy: 0.7600\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.8667\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8267\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.8800\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.5136 - val_accuracy: 0.8267\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.8400\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.8667\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.8667\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.8800\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 1s 7ms/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.8667\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 1s 6ms/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3809 - val_accuracy: 0.8667\n",
      "Training model 1 CNN\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 6s 36ms/sample - loss: 1.4506 - accuracy: 0.5033 - val_loss: 19.5277 - val_accuracy: 0.3600\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 1.0763 - accuracy: 0.8874 - val_loss: 9.6035 - val_accuracy: 0.3867\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 1.0279 - accuracy: 0.9404 - val_loss: 8.0702 - val_accuracy: 0.3867\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 1s 3ms/sample - loss: 0.9356 - accuracy: 0.9868 - val_loss: 4.7908 - val_accuracy: 0.4133\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 1s 4ms/sample - loss: 0.8706 - accuracy: 0.9934 - val_loss: 4.1096 - val_accuracy: 0.3600\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 1s 4ms/sample - loss: 0.7594 - accuracy: 1.0000 - val_loss: 3.4770 - val_accuracy: 0.3333\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 1s 4ms/sample - loss: 0.7055 - accuracy: 1.0000 - val_loss: 2.3531 - val_accuracy: 0.4533\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 1s 5ms/sample - loss: 0.6364 - accuracy: 1.0000 - val_loss: 2.0703 - val_accuracy: 0.4533\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.6012 - accuracy: 1.0000 - val_loss: 1.6075 - val_accuracy: 0.5067\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 1s 3ms/sample - loss: 0.5318 - accuracy: 1.0000 - val_loss: 1.2024 - val_accuracy: 0.6800\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.5132 - accuracy: 1.0000 - val_loss: 1.0171 - val_accuracy: 0.7867\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 1s 4ms/sample - loss: 0.4608 - accuracy: 1.0000 - val_loss: 0.9910 - val_accuracy: 0.7333\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 1s 4ms/sample - loss: 0.4499 - accuracy: 1.0000 - val_loss: 0.8402 - val_accuracy: 0.7867\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 1s 4ms/sample - loss: 0.3943 - accuracy: 1.0000 - val_loss: 0.8020 - val_accuracy: 0.8533\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.3728 - accuracy: 1.0000 - val_loss: 0.7608 - val_accuracy: 0.8933\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 1s 3ms/sample - loss: 0.3502 - accuracy: 0.9934 - val_loss: 0.7521 - val_accuracy: 0.8667\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.3731 - accuracy: 0.9934 - val_loss: 0.7830 - val_accuracy: 0.7867\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.3640 - accuracy: 0.9868 - val_loss: 0.6484 - val_accuracy: 0.8667\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 1s 3ms/sample - loss: 0.4089 - accuracy: 0.9801 - val_loss: 0.7371 - val_accuracy: 0.8133\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.4028 - accuracy: 0.9735 - val_loss: 0.7121 - val_accuracy: 0.8800\n",
      "Training model 2 InceptionTime\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 11s 72ms/sample - loss: 0.8559 - accuracy: 0.6954 - val_loss: 10.4376 - val_accuracy: 0.3600\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 0.1593 - accuracy: 0.9536 - val_loss: 22.4276 - val_accuracy: 0.2667\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 0.1006 - accuracy: 0.9536 - val_loss: 25.8605 - val_accuracy: 0.2667\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 0.0261 - accuracy: 0.9934 - val_loss: 23.2571 - val_accuracy: 0.2667\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 0.0336 - accuracy: 0.9868 - val_loss: 17.9154 - val_accuracy: 0.2800\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 1s 9ms/sample - loss: 0.0194 - accuracy: 0.9934 - val_loss: 12.1619 - val_accuracy: 0.3467\n",
      "Epoch 00006: early stopping\n",
      "Training model 3 CNN\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 11.3297 - accuracy: 0.6026 - val_loss: 10.9818 - val_accuracy: 0.7067\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 0s 984us/sample - loss: 7.6320 - accuracy: 0.9669 - val_loss: 7.1768 - val_accuracy: 0.7333\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 5.1260 - accuracy: 0.9470 - val_loss: 4.9807 - val_accuracy: 0.7600\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 3.6269 - accuracy: 0.9669 - val_loss: 3.7145 - val_accuracy: 0.7333\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 2.6814 - accuracy: 0.9934 - val_loss: 2.7587 - val_accuracy: 0.7600\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 2.0734 - accuracy: 0.9868 - val_loss: 2.3245 - val_accuracy: 0.7733\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 1.6868 - accuracy: 0.9934 - val_loss: 2.0121 - val_accuracy: 0.7600\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 0s 2ms/sample - loss: 1.4953 - accuracy: 0.9801 - val_loss: 1.8292 - val_accuracy: 0.7733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 1.3838 - accuracy: 0.9470 - val_loss: 1.7578 - val_accuracy: 0.7600\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 1.2920 - accuracy: 0.9404 - val_loss: 1.6947 - val_accuracy: 0.7333\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 1.1562 - accuracy: 0.9735 - val_loss: 1.5207 - val_accuracy: 0.7733\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 1.0927 - accuracy: 0.9735 - val_loss: 1.4505 - val_accuracy: 0.7733\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.9933 - accuracy: 0.9669 - val_loss: 1.4315 - val_accuracy: 0.7467\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.8713 - accuracy: 1.0000 - val_loss: 1.3224 - val_accuracy: 0.7467\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.8108 - accuracy: 0.9801 - val_loss: 1.3399 - val_accuracy: 0.7200\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.7695 - accuracy: 0.9669 - val_loss: 1.2536 - val_accuracy: 0.7733\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.7869 - accuracy: 0.9470 - val_loss: 1.3183 - val_accuracy: 0.7067\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.7210 - accuracy: 1.0000 - val_loss: 1.3130 - val_accuracy: 0.7333\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.6931 - accuracy: 0.9934 - val_loss: 1.2476 - val_accuracy: 0.7333\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.6010 - accuracy: 0.9868 - val_loss: 1.2888 - val_accuracy: 0.6267\n",
      "Training model 4 CNN\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 4s 24ms/sample - loss: 3.9158 - accuracy: 0.5828 - val_loss: 10.8585 - val_accuracy: 0.6400\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 5.0624 - accuracy: 0.9073 - val_loss: 8.0933 - val_accuracy: 0.6533\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 4.8143 - accuracy: 0.9735 - val_loss: 6.4836 - val_accuracy: 0.6533\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 4.0192 - accuracy: 0.9603 - val_loss: 4.9941 - val_accuracy: 0.6400\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 3.1182 - accuracy: 0.9934 - val_loss: 3.4103 - val_accuracy: 0.6800\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 2.4347 - accuracy: 0.9934 - val_loss: 2.8470 - val_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 1.9041 - accuracy: 0.9934 - val_loss: 2.1540 - val_accuracy: 0.7467\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 1.5581 - accuracy: 0.9868 - val_loss: 1.8004 - val_accuracy: 0.7867\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 1.2535 - accuracy: 0.9868 - val_loss: 1.4886 - val_accuracy: 0.8400\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.9934 - accuracy: 1.0000 - val_loss: 1.4281 - val_accuracy: 0.8400\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.8260 - accuracy: 1.0000 - val_loss: 1.3586 - val_accuracy: 0.7600\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.6940 - accuracy: 1.0000 - val_loss: 1.3125 - val_accuracy: 0.7467\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.6078 - accuracy: 0.9934 - val_loss: 1.2961 - val_accuracy: 0.6933\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.5777 - accuracy: 0.9934 - val_loss: 1.2914 - val_accuracy: 0.7467\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.5300 - accuracy: 0.9934 - val_loss: 1.1098 - val_accuracy: 0.7867\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.5047 - accuracy: 0.9801 - val_loss: 0.9791 - val_accuracy: 0.8133\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.4539 - accuracy: 0.9868 - val_loss: 1.1643 - val_accuracy: 0.7467\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.4106 - accuracy: 0.9934 - val_loss: 1.2082 - val_accuracy: 0.5867\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.4151 - accuracy: 0.9735 - val_loss: 1.2566 - val_accuracy: 0.5600\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 0s 3ms/sample - loss: 0.4337 - accuracy: 0.9669 - val_loss: 1.0199 - val_accuracy: 0.7333\n",
      "Training model 5 InceptionTime\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 8s 56ms/sample - loss: 0.8051 - accuracy: 0.7152 - val_loss: 4.4876 - val_accuracy: 0.4667\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 2s 14ms/sample - loss: 0.2252 - accuracy: 0.9404 - val_loss: 4.0818 - val_accuracy: 0.4000\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.1738 - accuracy: 0.9404 - val_loss: 3.8690 - val_accuracy: 0.4133\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0562 - accuracy: 1.0000 - val_loss: 3.4122 - val_accuracy: 0.3733\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 2s 14ms/sample - loss: 0.0461 - accuracy: 0.9934 - val_loss: 3.3737 - val_accuracy: 0.4800\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.7626 - val_accuracy: 0.7067\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.6895 - val_accuracy: 0.5600\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.9631 - val_accuracy: 0.4400\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 2s 14ms/sample - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.8519 - val_accuracy: 0.6400\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 0.7733\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 2s 14ms/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.9216 - val_accuracy: 0.7600\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 2s 14ms/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0721 - val_accuracy: 0.7600\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 0.7600\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5770 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5115 - val_accuracy: 0.8133\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 2s 14ms/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.8133\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0280 - accuracy: 0.9868 - val_loss: 0.4081 - val_accuracy: 0.8800\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.1736 - accuracy: 0.9669 - val_loss: 2.3490 - val_accuracy: 0.6267\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.1185 - accuracy: 0.9536 - val_loss: 1.2047 - val_accuracy: 0.7200\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0389 - accuracy: 0.9868 - val_loss: 0.8267 - val_accuracy: 0.7867\n",
      "Training model 6 CNN\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 1.2833 - accuracy: 0.5563 - val_loss: 1.2578 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.7191 - accuracy: 0.9272 - val_loss: 1.2042 - val_accuracy: 0.6933\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.6525 - accuracy: 0.9470 - val_loss: 1.1114 - val_accuracy: 0.7333\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.5805 - accuracy: 0.9801 - val_loss: 1.0561 - val_accuracy: 0.7600\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.6016 - accuracy: 0.9735 - val_loss: 1.0097 - val_accuracy: 0.7600\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.5353 - accuracy: 1.0000 - val_loss: 0.9793 - val_accuracy: 0.7600\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.5235 - accuracy: 1.0000 - val_loss: 0.9448 - val_accuracy: 0.7600\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.5306 - accuracy: 1.0000 - val_loss: 0.9169 - val_accuracy: 0.7733\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.5152 - accuracy: 1.0000 - val_loss: 0.8912 - val_accuracy: 0.7867\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.4850 - accuracy: 1.0000 - val_loss: 0.8709 - val_accuracy: 0.7867\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.4665 - accuracy: 1.0000 - val_loss: 0.8511 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.4963 - accuracy: 1.0000 - val_loss: 0.8370 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.4689 - accuracy: 1.0000 - val_loss: 0.8386 - val_accuracy: 0.8133\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.4885 - accuracy: 1.0000 - val_loss: 0.8381 - val_accuracy: 0.8133\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.4641 - accuracy: 1.0000 - val_loss: 0.8270 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.4667 - accuracy: 1.0000 - val_loss: 0.8176 - val_accuracy: 0.8133\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.4548 - accuracy: 1.0000 - val_loss: 0.8171 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.4743 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.4606 - accuracy: 1.0000 - val_loss: 0.8171 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 0s 1ms/sample - loss: 0.4536 - accuracy: 1.0000 - val_loss: 0.8178 - val_accuracy: 0.8000\n",
      "Training model 7 InceptionTime\n",
      "Train on 151 samples, validate on 75 samples\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 11s 70ms/sample - loss: 0.9074 - accuracy: 0.6821 - val_loss: 415.6523 - val_accuracy: 0.2667\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.5056 - accuracy: 0.7815 - val_loss: 598.1390 - val_accuracy: 0.2667\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.2507 - accuracy: 0.9205 - val_loss: 420.4679 - val_accuracy: 0.2667\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.1646 - accuracy: 0.9404 - val_loss: 191.3671 - val_accuracy: 0.2667\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.1482 - accuracy: 0.9470 - val_loss: 94.2274 - val_accuracy: 0.2667\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0368 - accuracy: 0.9934 - val_loss: 128.1895 - val_accuracy: 0.2667\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0573 - accuracy: 0.9735 - val_loss: 105.8133 - val_accuracy: 0.2400\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.1431 - accuracy: 0.9272 - val_loss: 168.4964 - val_accuracy: 0.2667\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.1917 - accuracy: 0.9139 - val_loss: 58.7867 - val_accuracy: 0.2667\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.2187 - accuracy: 0.9007 - val_loss: 81.1334 - val_accuracy: 0.2667\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.1943 - accuracy: 0.9603 - val_loss: 82.2359 - val_accuracy: 0.2933\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0645 - accuracy: 0.9868 - val_loss: 84.1961 - val_accuracy: 0.2267\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0260 - accuracy: 1.0000 - val_loss: 49.4664 - val_accuracy: 0.3467\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0160 - accuracy: 1.0000 - val_loss: 26.9527 - val_accuracy: 0.4800\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 16.9202 - val_accuracy: 0.4933\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 10.6787 - val_accuracy: 0.5600\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 3s 17ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.1064 - val_accuracy: 0.6000\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 2s 16ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.9386 - val_accuracy: 0.6400\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.5662 - val_accuracy: 0.6933\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 2s 15ms/sample - loss: 0.0173 - accuracy: 0.9934 - val_loss: 1.7428 - val_accuracy: 0.7200\n"
     ]
    }
   ],
   "source": [
    "outputfile = os.path.join(resultpath, 'modelcomparison_2.json')\n",
    "histories, val_accuracies, val_losses = train_models_on_samples(X_train, y_train_binary,\n",
    "                                                                X_val, y_val_binary,\n",
    "                                                                models, nr_epochs=20,\n",
    "                                                                subset_size=300,\n",
    "                                                                early_stopping_patience = 5,\n",
    "                                                                verbose=True,\n",
    "                                                                outputfile=outputfile,\n",
    "                                                                metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model-type</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.0002508899689375268, 'regu...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.380934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.008102929671455617, 'regul...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.973510</td>\n",
       "      <td>0.402825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.712099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.0016297966098709998, 'regu...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>0.993378</td>\n",
       "      <td>0.019420</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>12.161851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.0019430892193161443, 'regu...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.986755</td>\n",
       "      <td>0.601033</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>1.288750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.008889925393993863, 'regul...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.433666</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.019946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 0.0007907590834387294, 'regu...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>0.986755</td>\n",
       "      <td>0.038861</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.826676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'learning_rate': 0.0005081261465795578, 'regu...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453622</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.817783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'learning_rate': 0.0045608494108193166, 'regu...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>0.993378</td>\n",
       "      <td>0.017331</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>1.742814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model     model-type  \\\n",
       "0  {'learning_rate': 0.0002508899689375268, 'regu...  InceptionTime   \n",
       "1  {'learning_rate': 0.008102929671455617, 'regul...            CNN   \n",
       "2  {'learning_rate': 0.0016297966098709998, 'regu...  InceptionTime   \n",
       "3  {'learning_rate': 0.0019430892193161443, 'regu...            CNN   \n",
       "4  {'learning_rate': 0.008889925393993863, 'regul...            CNN   \n",
       "5  {'learning_rate': 0.0007907590834387294, 'regu...  InceptionTime   \n",
       "6  {'learning_rate': 0.0005081261465795578, 'regu...            CNN   \n",
       "7  {'learning_rate': 0.0045608494108193166, 'regu...  InceptionTime   \n",
       "\n",
       "   train_accuracy  train_loss  val_accuracy   val_loss  \n",
       "0        1.000000    0.005574      0.866667   0.380934  \n",
       "1        0.973510    0.402825      0.880000   0.712099  \n",
       "2        0.993378    0.019420      0.346667  12.161851  \n",
       "3        0.986755    0.601033      0.626667   1.288750  \n",
       "4        0.966887    0.433666      0.733333   1.019946  \n",
       "5        0.986755    0.038861      0.786667   0.826676  \n",
       "6        1.000000    0.453622      0.800000   0.817783  \n",
       "7        0.993378    0.017331      0.720000   1.742814  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = 'accuracy'\n",
    "modelcomparisons_2 = pd.DataFrame({'model':[str(params) for model, params, model_types in models],\n",
    "                                'model-type':[str(model_types) for model, params, model_types in models],\n",
    "                                'train_{}'.format(metric): [history.history[metric][-1] for history in histories],\n",
    "                                'train_loss': [history.history['loss'][-1] for history in histories],\n",
    "                                'val_{}'.format(metric): [history.history['val_{}'.format(metric)][-1] for history in histories],\n",
    "                                'val_loss': [history.history['val_loss'][-1] for history in histories]\n",
    "                                })\n",
    "modelcomparisons_2.to_csv(os.path.join(resultpath, 'modelcomparisons_2.csv'))\n",
    "\n",
    "modelcomparisons_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2) Chose the best model and train longer\n",
    "Now that we found an effective architecture, we can choose the most promising model. For example, we can choose the model with the highest accuracy on the validation data set. To maximize this models performance, we will train this model on more data and more epochs.\n",
    "\n",
    "### data subset --> full dataset\n",
    "If we did the search above on a subset of the data only, than now is the time to train on the full dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type and parameters of the best model:\n",
      "CNN\n",
      "{'learning_rate': 0.008102929671455617, 'regularization_rate': 0.00011234135658673196, 'filters': array([69, 27, 25, 40, 87, 36]), 'fc_hidden_nodes': 1841}\n"
     ]
    }
   ],
   "source": [
    "best_model_index = np.argmax(val_accuracies)\n",
    "best_model, best_params, best_model_types = models[best_model_index]\n",
    "print('Model type and parameters of the best model:')\n",
    "print(best_model_types)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the best model on the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified the best model architecture out of our random pool of models we can continue by training the model on the full training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.engine.sequential.Sequential at 0x1d9998fc688>,\n",
       " {'learning_rate': 0.008102929671455617,\n",
       "  'regularization_rate': 0.00011234135658673196,\n",
       "  'filters': array([69, 27, 25, 40, 87, 36]),\n",
       "  'fc_hidden_nodes': 1841},\n",
       " 'CNN')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[best_model_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 CNN\n",
      "Train on 150 samples, validate on 75 samples\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 0s 2ms/sample - loss: 0.2637 - accuracy: 0.9667 - val_loss: 0.7022 - val_accuracy: 0.8400\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 3ms/sample - loss: 0.2750 - accuracy: 0.9867 - val_loss: 0.6932 - val_accuracy: 0.8400\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 3ms/sample - loss: 0.3578 - accuracy: 0.9533 - val_loss: 0.8209 - val_accuracy: 0.7600\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 3ms/sample - loss: 0.3415 - accuracy: 0.9667 - val_loss: 4.1832 - val_accuracy: 0.5200\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "#We make a copy of the model, to start training from fresh\n",
    "_,_,_ = train_models_on_samples(X_train, y_train_binary,\n",
    "                                X_val, y_val_binary,\n",
    "                                [models[best_model_index]], nr_epochs=50,\n",
    "                                subset_size=None,\n",
    "                                early_stopping_patience = 2,\n",
    "                                verbose=True,\n",
    "                                outputfile=outputfile,\n",
    "                                metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 7: Do you think it is useful to train with more than 1 epoch?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving, loading and comparing reloaded model with original model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can be saved for future use. The savemodel function will save two separate files: a json file for the architecture and a npy (numpy array) file for the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'my_bestmodel.h5'\n",
    "model_path = os.path.join(resultpath,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reloaded = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has been reloaded. Let's reassure that this model has the same weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all([np.all(x==y) for x,y in zip(best_model.get_weights(), model_reloaded.get_weights())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the objects `models`, `best_model_fullytrained` and `best_model` that resulted from the mcfly functions are Keras objects. This means that you can use Keras functions on the objects, for example  `.predict`, (which when given the data, outputs the predictions for each sample) and `.evaluate` (which when given the data and the labels computes how well this model performs) . These functions are all documented in the [Keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect model predictions on validation data\n",
    "datasize = X_val.shape[0]\n",
    "probs = models[0][0].predict(X_val[:datasize,:,:],batch_size=1)  # here a different model was chosen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Badminton_Clear</th>\n",
       "      <th>Badminton_Smash</th>\n",
       "      <th>Squash_BackhandBoast</th>\n",
       "      <th>Squash_ForehandBoast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Badminton_Clear</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Badminton_Smash</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Squash_BackhandBoast</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Squash_ForehandBoast</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Badminton_Clear  Badminton_Smash  Squash_BackhandBoast  \\\n",
       "Badminton_Clear                    17                4                     0   \n",
       "Badminton_Smash                     6               14                     0   \n",
       "Squash_BackhandBoast                0                0                    17   \n",
       "Squash_ForehandBoast                0                0                     0   \n",
       "\n",
       "                      Squash_ForehandBoast  \n",
       "Badminton_Clear                          0  \n",
       "Badminton_Smash                          0  \n",
       "Squash_BackhandBoast                     0  \n",
       "Squash_ForehandBoast                    17  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns are predicted, rows are truth\n",
    "labels = lb.classes_\n",
    "\n",
    "predicted = probs.argmax(axis=1)\n",
    "y_index = y_val_binary.argmax(axis=1)\n",
    "confusion_matrix = pd.crosstab(pd.Series(y_index), pd.Series(predicted))\n",
    "confusion_matrix.index = [labels[i] for i in confusion_matrix.index]\n",
    "confusion_matrix.columns = [labels[i] for i in confusion_matrix.columns]\n",
    "confusion_matrix.reindex(columns=[l for l in labels], fill_value=0)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

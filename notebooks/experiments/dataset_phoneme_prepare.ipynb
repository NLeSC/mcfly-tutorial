{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: PhonemeSpectra\n",
    "\n",
    "http://www.timeseriesclassification.com/description.php?Dataset=PhonemeSpectra\n",
    "\n",
    "### Info from data source:\n",
    "Phoneme Description:\n",
    "This data set is a multivaritate representation of a subset of the data used in the paper Dual-domain Hierarchical Classification of Phonetic Time Series. \n",
    "In the case of the raw data.\n",
    "Each series was extracted from the segmented audio collected from Google Translate\n",
    "Audio files collected from Google translate are recorded at 22050\n",
    "The speakers are male and female.\n",
    "After data collection, they segment waveforms of the words to generate phonemes using the Forced Aligner tool from the Penn Phonetics Laboratory.\n",
    "A Spectrogram of each instance was then created with a window size of 0.001 seconds and an overlap of 90%.\n",
    "Each instance in this multivariate dataset is arranged such that each dimension is a frequency band from the spectrogram.\n",
    "The data consists of 39 classes each with 170 instances. \n",
    "\n",
    "Phoneme Refference:\n",
    "Publication: Hamooni H, Mueen A. Dual-domain hierarchical classification of phonetic time series. InData Mining (ICDM), 2014 IEEE International Conference on 2014 Dec 14 (pp. 160-169). IEEE.\n",
    "\n",
    "\n",
    "### Size:\n",
    "+ Training samples: 3315\n",
    "+ Test sampels: 3353\n",
    "+ Dimension: 217 timepoints x 11 channels\n",
    "+ Classes: 39\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "CODE = 'C:\\\\OneDrive - Netherlands eScience Center\\\\Project_mcfly\\\\mcfly\\\\mcfly'\n",
    "DATA = 'C:\\\\OneDrive - Netherlands eScience Center\\\\Project_mcfly\\\\data\\\\PhonemeSpectra'\n",
    "sys.path.append(CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train = os.path.join(DATA, 'PhonemeSpectra_TRAIN.arff')\n",
    "file_test = os.path.join(DATA, 'PhonemeSpectra_TEST.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arff(filename):\n",
    "    start = 0\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "    start_line = 0\n",
    "    with open(filename) as fp:\n",
    "        line = fp.readline()\n",
    "        count = 0\n",
    "        while line:\n",
    "            if start == 1:\n",
    "                label = line.split(\"',\")[-1]\n",
    "                labels.append(label)\n",
    "                line = line.split(\"',\")[0] \n",
    "                lines = line.split('\\\\n')\n",
    "                data_line = []\n",
    "                for l in lines:\n",
    "                    data_line_sub = []\n",
    "                    #for entry in l.split(','):\n",
    "                        #data_line_sub.append(entry.replace(\"'\", \"\"))\n",
    "                    #data_line.append(data_line_sub)\n",
    "                    data_line.append([x.replace(\"'\", \"\") for x in l.split(',')])\n",
    "                data.append(data_line)\n",
    "\n",
    "            if line.startswith('@data'):\n",
    "                start_line = count\n",
    "                #print(\"Actual data start in line\", start_line)\n",
    "                start = 1\n",
    "\n",
    "            line = fp.readline()\n",
    "            count += 1\n",
    "            \n",
    "    return np.swapaxes(np.array(data).astype(float), 1,2), labels\n",
    "\n",
    "X_train, y_train = load_arff(file_train)\n",
    "X_test0, y_test0 = load_arff(file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (3315, 217, 11)\n",
      "3315\n",
      "X_test.shape (3353, 217, 11)\n",
      "3353\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(len(y_train))\n",
    "\n",
    "print(\"X_test.shape\", X_test0.shape)\n",
    "print(len(y_test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.60185 ,  0.10432 ,  0.67014 ,  0.15635 ,  0.95577 ,  2.4809  ,\n",
       "        3.5833  ,  4.7018  ,  1.1286  ,  7.2648  ,  7.1282  ,  5.3625  ,\n",
       "        4.6666  ,  3.4076  ,  3.4368  ,  3.1312  ,  0.6371  ,  7.2779  ,\n",
       "       10.702   ,  9.528   ,  8.9655  ,  5.3169  ,  2.2338  ,  0.31894 ,\n",
       "        1.8213  ,  6.7641  , 10.24    ,  9.8695  ,  7.5672  ,  2.3384  ,\n",
       "        3.8596  ,  7.3618  ,  3.3751  ,  2.6142  ,  2.605   ,  5.3137  ,\n",
       "        5.4795  ,  1.0734  ,  1.0891  ,  3.0922  ,  2.4679  ,  0.091312,\n",
       "        2.8001  ,  6.1137  ,  4.8455  ,  0.27992 ,  3.3654  ,  7.6773  ,\n",
       "        9.0268  , 12.636   , 12.903   ,  8.7211  ,  8.656   ,  9.1178  ,\n",
       "        5.2904  ,  3.632   ,  6.6237  ,  6.1359  ,  5.684   ,  5.1734  ,\n",
       "        5.4562  ,  5.3652  ,  5.2969  ,  4.7929  ,  8.4382  ,  9.1113  ,\n",
       "        2.4906  ,  1.5931  ,  1.2522  ,  5.8437  ,  8.9623  ,  5.8633  ,\n",
       "        4.0618  ,  2.3871  ,  0.9758  ,  0.74115 ,  0.95252 ,  2.296   ,\n",
       "        2.6277  ,  3.1806  ,  5.8372  ,  7.1867  ,  6.8454  ,  7.0274  ,\n",
       "        7.4567  ,  7.5445  ,  8.2956  ,  8.7867  ,  9.5703  ,  9.6614  ,\n",
       "        6.9689  ,  6.7347  ,  6.712   ,  6.6502  ,  5.4763  ,  7.4989  ,\n",
       "       10.647   , 10.585   , 13.574   , 12.874   ,  9.4045  ,  4.3024  ,\n",
       "        2.3578  ,  2.7995  ,  9.5959  , 11.085   , 14.688   , 23.92    ,\n",
       "       24.843   , 15.833   , 15.885   , 10.116   ,  0.064775,  0.21435 ,\n",
       "        2.4158  ,  4.9229  , 11.127   , 10.916   ,  9.921   , 15.599   ,\n",
       "        6.9587  ,  2.6044  ,  7.4561  ,  4.5035  ,  1.6945  ,  2.1947  ,\n",
       "        0.38345 ,  3.7951  ,  4.4358  ,  3.7496  ,  3.6163  ,  0.075052,\n",
       "        1.5281  ,  5.4953  , 10.812   ,  5.4921  ,  4.9458  ,  2.1915  ,\n",
       "        4.9495  ,  9.0468  ,  2.0749  ,  6.2465  ,  5.8107  ,  2.6565  ,\n",
       "        1.4825  ,  4.6081  , 12.673   , 11.932   ,  2.3514  ,  5.2352  ,\n",
       "        6.3863  ,  7.3098  ,  5.3262  ,  3.6293  , 15.082   , 16.552   ,\n",
       "       15.859   , 14.896   , 12.448   ,  6.0291  ,  7.4729  ,  9.2094  ,\n",
       "        9.9443  , 11.121   , 13.275   , 12.555   , 10.507   ,  9.9053  ,\n",
       "       10.276   , 14.081   , 14.197   , 13.947   , 14.377   , 12.884   ,\n",
       "        3.0764  ,  1.0143  ,  0.20187 ,  1.1606  ,  4.1881  ,  3.5605  ,\n",
       "        3.5995  ,  6.318   , 11.144   , 24.688   , 17.897   , 13.641   ,\n",
       "       22.681   , 14.932   ,  3.3139  ,  7.0139  ,  7.6578  ,  2.8255  ,\n",
       "       12.825   , 14.344   , 13.261   , 17.232   ,  5.0401  ,  1.6977  ,\n",
       "        7.4301  ,  1.7822  ,  2.127   , 10.519   ,  7.9993  ,  0.14984 ,\n",
       "        4.3669  ,  3.8276  ,  7.9119  ,  2.5725  ,  3.0662  ,  8.3439  ,\n",
       "       14.206   ,  8.643   ,  0.57531 ,  1.9058  , 13.368   , 12.279   ,\n",
       "        1.3264  ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,:,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot test into test and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n",
      " 86\n",
      "NG\n",
      " 86\n",
      "JH\n",
      " 86\n",
      "AH\n",
      " 86\n",
      "Z\n",
      " 86\n",
      "AY\n",
      " 86\n",
      "IY\n",
      " 86\n",
      "S\n",
      " 86\n",
      "B\n",
      " 86\n",
      "AE\n",
      " 86\n",
      "G\n",
      " 86\n",
      "ZH\n",
      " 85\n",
      "AO\n",
      " 86\n",
      "P\n",
      " 86\n",
      "V\n",
      " 86\n",
      "HH\n",
      " 86\n",
      "D\n",
      " 86\n",
      "F\n",
      " 86\n",
      "OY\n",
      " 86\n",
      "K\n",
      " 86\n",
      "AW\n",
      " 86\n",
      "OW\n",
      " 86\n",
      "UH\n",
      " 86\n",
      "UW\n",
      " 86\n",
      "AA\n",
      " 86\n",
      "SH\n",
      " 86\n",
      "R\n",
      " 86\n",
      "EY\n",
      " 86\n",
      "DH\n",
      " 86\n",
      "M\n",
      " 86\n",
      "ER\n",
      " 86\n",
      "Y\n",
      " 86\n",
      "T\n",
      " 86\n",
      "CH\n",
      " 86\n",
      "EH\n",
      " 86\n",
      "L\n",
      " 86\n",
      "IH\n",
      " 86\n",
      "N\n",
      " 86\n",
      "TH\n",
      " 86\n"
     ]
    }
   ],
   "source": [
    "y_val = []\n",
    "y_test = []\n",
    "IDs_val = []\n",
    "IDs_test = []\n",
    "\n",
    "np.random.seed(1)\n",
    "for label in list(set(y_test0)):\n",
    "    idx = np.where(np.array(y_test0) == label)[0]\n",
    "    idx1 = np.random.choice(idx, len(idx)//2, replace=False)\n",
    "    idx2 = list(set(idx) - set(idx1))\n",
    "    IDs_val.extend(idx1)\n",
    "    IDs_test.extend(idx2)\n",
    "    y_val.extend(len(idx1) * [label])\n",
    "    y_test.extend(len(idx2) * [label])\n",
    "\n",
    "    print(label, y_test0.count(label))\n",
    "    \n",
    "X_test = X_test0[IDs_test,:,:]\n",
    "X_val = X_test0[IDs_val,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1677, 217, 11) (1676, 217, 11)\n",
      "1677 1676\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, X_val.shape)\n",
    "print(len(y_test), len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save pre-processed data as numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'PhenomeSpectra_'\n",
    "\n",
    "output_path = 'C:\\\\OneDrive - Netherlands eScience Center\\\\Project_mcfly\\\\data\\\\processed'\n",
    "np.save(os.path.join(output_path, dataset_name + 'X_train.npy'), X_train)\n",
    "np.save(os.path.join(output_path, dataset_name + 'X_val.npy'), X_val)\n",
    "np.save(os.path.join(output_path, dataset_name + 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(output_path, dataset_name + 'y_train.npy'), y_train)\n",
    "np.save(os.path.join(output_path, dataset_name + 'y_val.npy'), y_val)\n",
    "np.save(os.path.join(output_path, dataset_name + 'y_test.npy'), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or: Create new split of data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

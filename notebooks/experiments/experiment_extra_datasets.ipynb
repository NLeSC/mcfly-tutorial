{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "DATA = 'C:\\\\OneDrive - Netherlands eScience Center\\\\Project_mcfly\\\\data\\\\processed'\n",
    "CODE = 'C:\\\\OneDrive - Netherlands eScience Center\\\\Project_mcfly\\\\mcfly\\\\mcfly'\n",
    "sys.path.append(CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modelgen, find_architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: RacketSports dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'RacketSports_'\n",
    "\n",
    "X_train = np.load(os.path.join(DATA, dataset_name + 'X_train.npy'))\n",
    "X_val = np.load(os.path.join(DATA, dataset_name + 'X_val.npy'))\n",
    "X_test = np.load(os.path.join(DATA, dataset_name + 'X_test.npy'))\n",
    "y_train = np.load(os.path.join(DATA, dataset_name + 'y_train.npy'))\n",
    "y_val = np.load(os.path.join(DATA, dataset_name + 'y_val.npy'))\n",
    "y_test = np.load(os.path.join(DATA, dataset_name + 'y_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 30, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: ['Squash_BackhandBoast', 'Squash_ForehandBoast', 'Badminton_Clear', 'Badminton_Smash']\n"
     ]
    }
   ],
   "source": [
    "labels_unique = list(set(y_train))\n",
    "print(\"Unique labels:\", labels_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Badminton_Clear', 'Badminton_Smash', 'Squash_BackhandBoast',\n",
       "       'Squash_ForehandBoast'], dtype='<U20')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(labels_unique)\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = lb.fit_transform(y_train)\n",
    "y_val_binary = lb.fit_transform(y_val)\n",
    "y_test_binary = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set maximum kernel size for InceptionTime models to number of timesteps.\n"
     ]
    }
   ],
   "source": [
    "num_classes = y_train_binary.shape[1]\n",
    "\n",
    "models = modelgen.generate_models(X_train.shape,\n",
    "                                  number_of_classes=num_classes,\n",
    "                                  number_of_models = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tensorflow.python.keras.engine.sequential.Sequential at 0x2248d87bda0>,\n",
       "  {'learning_rate': 0.0005966846031985653,\n",
       "   'regularization_rate': 0.0003215011280140589,\n",
       "   'filters': [29, 29, 84, 39, 55, 75, 64, 90, 73],\n",
       "   'lstm_dims': [19, 21]},\n",
       "  'DeepConvLSTM'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x2248eae19e8>,\n",
       "  {'learning_rate': 0.005704344538439795,\n",
       "   'regularization_rate': 0.051094988802830046,\n",
       "   'filters': array([36, 91, 90, 97, 73, 87]),\n",
       "   'fc_hidden_nodes': 237},\n",
       "  'CNN'),\n",
       " (<tensorflow.python.keras.engine.training.Model at 0x22491646b70>,\n",
       "  {'learning_rate': 0.00040098743303156796,\n",
       "   'regularization_rate': 0.001715960521287867,\n",
       "   'network_depth': 6,\n",
       "   'filters_number': 51,\n",
       "   'max_kernel_size': 13},\n",
       "  'InceptionTime'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x2249168c4e0>,\n",
       "  {'learning_rate': 0.01867479999611516,\n",
       "   'regularization_rate': 0.09862431296512233,\n",
       "   'filters': array([91, 71, 47, 37, 60, 75, 16]),\n",
       "   'fc_hidden_nodes': 107},\n",
       "  'CNN'),\n",
       " (<tensorflow.python.keras.engine.training.Model at 0x22494216470>,\n",
       "  {'learning_rate': 0.007611540255162417,\n",
       "   'regularization_rate': 0.00010435729285514664,\n",
       "   'network_depth': 6,\n",
       "   'filters_number': 50,\n",
       "   'max_kernel_size': 12},\n",
       "  'InceptionTime'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x22494237d68>,\n",
       "  {'learning_rate': 0.02884843370772583,\n",
       "   'regularization_rate': 0.03754799010047728,\n",
       "   'filters': [75, 88, 46, 13, 10, 68, 97],\n",
       "   'lstm_dims': [64, 55, 36, 36]},\n",
       "  'DeepConvLSTM')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = models[0][0].metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d77d2ac19e56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "metric.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 DeepConvLSTM\n",
      "Train on 150 samples, validate on 75 samples\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 1.5450 - acc: 0.3333 - val_loss: 1.5541 - val_acc: 0.2800\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 1.5112 - acc: 0.3867 - val_loss: 1.5513 - val_acc: 0.3600\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.4192 - acc: 0.4733 - val_loss: 1.5485 - val_acc: 0.3867\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 1.3167 - acc: 0.5600 - val_loss: 1.5469 - val_acc: 0.2400\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 1.1936 - acc: 0.6467 - val_loss: 1.5396 - val_acc: 0.2400\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 1.0179 - acc: 0.7933 - val_loss: 1.5342 - val_acc: 0.3733\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.9544 - acc: 0.7467 - val_loss: 1.5288 - val_acc: 0.3333\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.8419 - acc: 0.8533 - val_loss: 1.5362 - val_acc: 0.3067\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.7227 - acc: 0.9133 - val_loss: 1.5067 - val_acc: 0.3200\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.6339 - acc: 0.9067 - val_loss: 1.5245 - val_acc: 0.2933\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.6141 - acc: 0.9267 - val_loss: 1.4609 - val_acc: 0.3733\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.5862 - acc: 0.9667 - val_loss: 1.4074 - val_acc: 0.4400\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.5419 - acc: 0.9200 - val_loss: 1.4706 - val_acc: 0.4400\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.4998 - acc: 0.9467 - val_loss: 1.3722 - val_acc: 0.4533\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.4793 - acc: 0.9667 - val_loss: 1.1371 - val_acc: 0.5867\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.4528 - acc: 0.9800 - val_loss: 1.1048 - val_acc: 0.6400\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.4200 - acc: 0.9533 - val_loss: 0.9583 - val_acc: 0.6800\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.4095 - acc: 0.9600 - val_loss: 0.8785 - val_acc: 0.7333\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.3934 - acc: 0.9533 - val_loss: 0.8052 - val_acc: 0.7733\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.4242 - acc: 0.9467 - val_loss: 0.6734 - val_acc: 0.8000\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.3512 - acc: 0.9733 - val_loss: 0.6512 - val_acc: 0.8400\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.3019 - acc: 0.9933 - val_loss: 0.8193 - val_acc: 0.7733\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.2974 - acc: 0.9933 - val_loss: 0.8532 - val_acc: 0.7600\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.2727 - acc: 1.0000 - val_loss: 0.8943 - val_acc: 0.7733\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.2640 - acc: 0.9933 - val_loss: 0.8994 - val_acc: 0.7867\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.2782 - acc: 0.9933 - val_loss: 0.9285 - val_acc: 0.7867\n",
      "Epoch 00026: early stopping\n",
      "Training model 1 CNN\n",
      "Train on 150 samples, validate on 75 samples\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 3s 23ms/step - loss: 32.6699 - acc: 0.4867 - val_loss: 27.3965 - val_acc: 0.3867\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 19.9603 - acc: 0.8400 - val_loss: 14.4668 - val_acc: 0.3600\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 10.7367 - acc: 0.9000 - val_loss: 8.1976 - val_acc: 0.3733\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 5.9813 - acc: 0.8600 - val_loss: 5.2866 - val_acc: 0.4000\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.6648 - acc: 0.9400 - val_loss: 3.8971 - val_acc: 0.2800\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.5096 - acc: 0.8800 - val_loss: 3.1618 - val_acc: 0.2800\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.0808 - acc: 0.8667 - val_loss: 2.9125 - val_acc: 0.3333\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.9667 - acc: 0.8333 - val_loss: 3.0174 - val_acc: 0.2800\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.9527 - acc: 0.9067 - val_loss: 2.8256 - val_acc: 0.2800\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.7002 - acc: 0.8867 - val_loss: 2.5607 - val_acc: 0.2800\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.4441 - acc: 0.9067 - val_loss: 2.2888 - val_acc: 0.2800\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3209 - acc: 0.8600 - val_loss: 2.2689 - val_acc: 0.2800\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.4736 - acc: 0.8267 - val_loss: 2.3861 - val_acc: 0.3600\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.6527 - acc: 0.8600 - val_loss: 2.5850 - val_acc: 0.4000\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5473 - acc: 0.8867 - val_loss: 2.2715 - val_acc: 0.4533\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2706 - acc: 0.9267 - val_loss: 2.1963 - val_acc: 0.2800\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2831 - acc: 0.8067 - val_loss: 2.2402 - val_acc: 0.2800\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2621 - acc: 0.8933 - val_loss: 2.3334 - val_acc: 0.2800\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5998 - acc: 0.7800 - val_loss: 4.0812 - val_acc: 0.2267\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5518 - acc: 0.8933 - val_loss: 2.3021 - val_acc: 0.2800\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3127 - acc: 0.8733 - val_loss: 2.1570 - val_acc: 0.3733\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2416 - acc: 0.8667 - val_loss: 2.1620 - val_acc: 0.2800\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2842 - acc: 0.8600 - val_loss: 2.0614 - val_acc: 0.3067\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1128 - acc: 0.9200 - val_loss: 2.0606 - val_acc: 0.2800\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.9474 - acc: 0.9533 - val_loss: 1.9607 - val_acc: 0.2800\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1446 - acc: 0.8533 - val_loss: 2.1495 - val_acc: 0.3067\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3617 - acc: 0.8533 - val_loss: 2.2605 - val_acc: 0.5200\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.8194 - acc: 0.8533 - val_loss: 2.7627 - val_acc: 0.4533\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.8213 - acc: 0.8933 - val_loss: 2.3043 - val_acc: 0.5733\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.6726 - acc: 0.8800 - val_loss: 1.9605 - val_acc: 0.6133\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.4195 - acc: 0.8733 - val_loss: 1.9549 - val_acc: 0.5333\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2955 - acc: 0.8800 - val_loss: 2.2227 - val_acc: 0.2667\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.4017 - acc: 0.8800 - val_loss: 2.1164 - val_acc: 0.4533\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.3390 - acc: 0.8933 - val_loss: 2.5760 - val_acc: 0.3867\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 2ms/step - loss: 1.2841 - acc: 0.8667 - val_loss: 2.2163 - val_acc: 0.4533\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1323 - acc: 0.9067 - val_loss: 2.1679 - val_acc: 0.2933\n",
      "Epoch 00036: early stopping\n",
      "Training model 2 InceptionTime\n",
      "Train on 150 samples, validate on 75 samples\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 5s 31ms/step - loss: 1.0312 - acc: 0.6200 - val_loss: 4.1984 - val_acc: 0.2667\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.4727 - acc: 0.8933 - val_loss: 2.8748 - val_acc: 0.2667\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2868 - acc: 0.9400 - val_loss: 2.3714 - val_acc: 0.2667\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.1831 - acc: 0.9800 - val_loss: 1.7817 - val_acc: 0.4000\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.1082 - acc: 0.9933 - val_loss: 1.3536 - val_acc: 0.4800\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0593 - acc: 1.0000 - val_loss: 1.2223 - val_acc: 0.5867\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0385 - acc: 1.0000 - val_loss: 1.0773 - val_acc: 0.6267\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0454 - acc: 1.0000 - val_loss: 0.7767 - val_acc: 0.6800\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.6413 - val_acc: 0.7067\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6713 - val_acc: 0.7467\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0126 - acc: 1.000 - 1s 4ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.6585 - val_acc: 0.7333\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.5852 - val_acc: 0.7333\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4985 - val_acc: 0.7733\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4379 - val_acc: 0.7867\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4038 - val_acc: 0.7867\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3996 - val_acc: 0.8267\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.3649 - val_acc: 0.8133\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.3495 - val_acc: 0.8667\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3344 - val_acc: 0.8800\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.3357 - val_acc: 0.8933\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.3704 - val_acc: 0.8933\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4241 - val_acc: 0.8000\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.3388 - val_acc: 0.9067\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.3358 - val_acc: 0.9067\n",
      "Epoch 00024: early stopping\n",
      "Training model 3 CNN\n",
      "Train on 150 samples, validate on 75 samples\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 4s 27ms/step - loss: 36.5604 - acc: 0.4867 - val_loss: 28.7369 - val_acc: 0.3200\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 13.8357 - acc: 0.5733 - val_loss: 8.7071 - val_acc: 0.3600\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 6.7848 - acc: 0.6267 - val_loss: 5.7904 - val_acc: 0.2267\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.8789 - acc: 0.5733 - val_loss: 4.5239 - val_acc: 0.2400\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.8789 - acc: 0.6333 - val_loss: 4.0966 - val_acc: 0.2267\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.6352 - acc: 0.7133 - val_loss: 4.1217 - val_acc: 0.5067\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.3297 - acc: 0.7800 - val_loss: 3.6787 - val_acc: 0.2667\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.1399 - acc: 0.6867 - val_loss: 3.6096 - val_acc: 0.3467\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.5384 - acc: 0.7400 - val_loss: 2.9253 - val_acc: 0.2800\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.6573 - acc: 0.5867 - val_loss: 9.1286 - val_acc: 0.2800\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.3857 - acc: 0.7000 - val_loss: 3.4773 - val_acc: 0.3067\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 2.7402 - acc: 0.7267 - val_loss: 3.5523 - val_acc: 0.2267\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 4.0489 - acc: 0.6133 - val_loss: 8.8464 - val_acc: 0.4267\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 3.8012 - acc: 0.7333 - val_loss: 3.2957 - val_acc: 0.3200\n",
      "Epoch 00014: early stopping\n",
      "Training model 4 InceptionTime\n",
      "Train on 150 samples, validate on 75 samples\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 5s 33ms/step - loss: 0.9353 - acc: 0.6133 - val_loss: 11.8770 - val_acc: 0.2533\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2780 - acc: 0.8533 - val_loss: 11.8199 - val_acc: 0.2667\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.1894 - acc: 0.9200 - val_loss: 11.8199 - val_acc: 0.2667\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.1840 - acc: 0.9267 - val_loss: 11.8199 - val_acc: 0.2667\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.1280 - acc: 0.9600 - val_loss: 12.1375 - val_acc: 0.2400\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0703 - acc: 0.9933 - val_loss: 10.0717 - val_acc: 0.3600\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0517 - acc: 0.9933 - val_loss: 8.1628 - val_acc: 0.4667\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0935 - acc: 0.9667 - val_loss: 11.6420 - val_acc: 0.2667\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0455 - acc: 0.9800 - val_loss: 10.9243 - val_acc: 0.2400\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1644 - acc: 0.942 - 1s 4ms/step - loss: 0.3070 - acc: 0.9267 - val_loss: 8.6068 - val_acc: 0.4267\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.1780 - acc: 0.9267 - val_loss: 12.4501 - val_acc: 0.2267\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0775 - acc: 0.9733 - val_loss: 8.5574 - val_acc: 0.4533\n",
      "Epoch 00012: early stopping\n",
      "Training model 5 DeepConvLSTM\n",
      "Train on 150 samples, validate on 75 samples\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 9s 59ms/step - loss: 8.4010 - acc: 0.2600 - val_loss: 5.1483 - val_acc: 0.2800\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 3.8294 - acc: 0.2667 - val_loss: 2.6401 - val_acc: 0.2267\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 2.4394 - acc: 0.2600 - val_loss: 1.9263 - val_acc: 0.2800\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.7537 - acc: 0.2667 - val_loss: 1.6030 - val_acc: 0.2800\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.5533 - acc: 0.2000 - val_loss: 1.4780 - val_acc: 0.2667\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.4530 - acc: 0.2600 - val_loss: 1.4235 - val_acc: 0.2800\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 2s 15ms/step - loss: 1.4202 - acc: 0.2867 - val_loss: 1.4084 - val_acc: 0.2800\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.4000 - acc: 0.2867 - val_loss: 1.3948 - val_acc: 0.2800\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.3907 - acc: 0.3000 - val_loss: 1.3884 - val_acc: 0.2800\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 1.3892 - acc: 0.2933 - val_loss: 1.3856 - val_acc: 0.2800\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.3855 - acc: 0.2933 - val_loss: 1.3859 - val_acc: 0.2800\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 1.3878 - acc: 0.2867 - val_loss: 1.3846 - val_acc: 0.2800\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.3835 - acc: 0.2867 - val_loss: 1.3836 - val_acc: 0.2800\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.3850 - acc: 0.2867 - val_loss: 1.3831 - val_acc: 0.2800\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 1.3859 - acc: 0.2867 - val_loss: 1.3829 - val_acc: 0.2800\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.3833 - acc: 0.2867 - val_loss: 1.3828 - val_acc: 0.2800\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.3824 - acc: 0.2867 - val_loss: 1.3829 - val_acc: 0.2800\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.3833 - acc: 0.2867 - val_loss: 1.3833 - val_acc: 0.2800\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.3825 - acc: 0.2867 - val_loss: 1.3834 - val_acc: 0.2800\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 2s 17ms/step - loss: 1.3829 - acc: 0.2867 - val_loss: 1.3840 - val_acc: 0.2800\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 3s 17ms/step - loss: 1.3831 - acc: 0.2867 - val_loss: 1.3827 - val_acc: 0.2800\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 3s 18ms/step - loss: 1.3822 - acc: 0.2867 - val_loss: 1.3829 - val_acc: 0.2800\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 3s 17ms/step - loss: 1.3839 - acc: 0.2867 - val_loss: 1.3832 - val_acc: 0.2800\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 2s 16ms/step - loss: 1.3806 - acc: 0.3000 - val_loss: 1.3831 - val_acc: 0.2800\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 2s 16ms/step - loss: 1.3842 - acc: 0.2800 - val_loss: 1.3835 - val_acc: 0.2800\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 1.3825 - acc: 0.2867 - val_loss: 1.3844 - val_acc: 0.2800\n",
      "Epoch 00026: early stopping\n",
      "Details of the training process were stored in  C:\\OneDrive - Netherlands eScience Center\\Project_mcfly\\trained_models\\modelcomparison.json\n"
     ]
    }
   ],
   "source": [
    "resultpath = 'C:\\\\OneDrive - Netherlands eScience Center\\\\Project_mcfly\\\\trained_models'\n",
    "outputfile = os.path.join(resultpath, 'modelcomparison.json')\n",
    "histories, val_accuracies, val_losses = find_architecture.train_models_on_samples(X_train, y_train_binary,\n",
    "                                                                           X_val, y_val_binary,\n",
    "                                                                           models,nr_epochs=50,\n",
    "                                                                           subset_size=-1,\n",
    "                                                                           verbose=True,\n",
    "                                                                           outputfile=outputfile)\n",
    "print('Details of the training process were stored in ',outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.0005966846031985653, 'regu...</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.278233</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.928452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.005704344538439795, 'regul...</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>1.132318</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>2.167861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.00040098743303156796, 'reg...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.335827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.01867479999611516, 'regula...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>3.801166</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>3.295653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.007611540255162417, 'regul...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.077482</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>8.557407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 0.02884843370772583, 'regula...</td>\n",
       "      <td>0.286667</td>\n",
       "      <td>1.382530</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>1.384362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  train_acc  train_loss  \\\n",
       "0  {'learning_rate': 0.0005966846031985653, 'regu...   0.993333    0.278233   \n",
       "1  {'learning_rate': 0.005704344538439795, 'regul...   0.906667    1.132318   \n",
       "2  {'learning_rate': 0.00040098743303156796, 'reg...   1.000000    0.004418   \n",
       "3  {'learning_rate': 0.01867479999611516, 'regula...   0.733333    3.801166   \n",
       "4  {'learning_rate': 0.007611540255162417, 'regul...   0.973333    0.077482   \n",
       "5  {'learning_rate': 0.02884843370772583, 'regula...   0.286667    1.382530   \n",
       "\n",
       "    val_acc  val_loss  \n",
       "0  0.786667  0.928452  \n",
       "1  0.293333  2.167861  \n",
       "2  0.906667  0.335827  \n",
       "3  0.320000  3.295653  \n",
       "4  0.453333  8.557407  \n",
       "5  0.280000  1.384362  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelcomparisons = pd.DataFrame({'model':[str(params) for model, params, model_types in models],\n",
    "                       'train_acc': [history.history['acc'][-1] for history in histories],\n",
    "                       'train_loss': [history.history['loss'][-1] for history in histories],\n",
    "                       'val_acc': [history.history['val_acc'][-1] for history in histories],\n",
    "                       'val_loss': [history.history['val_loss'][-1] for history in histories]\n",
    "                       })\n",
    "modelcomparisons.to_csv(os.path.join(resultpath, 'modelcomparisons.csv'))\n",
    "\n",
    "modelcomparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DeepConvLSTM',\n",
       " 'CNN',\n",
       " 'InceptionTime',\n",
       " 'CNN',\n",
       " 'InceptionTime',\n",
       " 'DeepConvLSTM']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[-1] for x in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 6)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 30, 32)       192         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 30, 6)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 30, 51)       21216       conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 30, 51)       9792        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 30, 51)       4896        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 30, 51)       306         max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30, 204)      0           conv1d_7[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 30, 204)      816         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 30, 204)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 30, 32)       6528        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 30, 204)      0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 30, 51)       21216       conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 30, 51)       9792        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 30, 51)       4896        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 30, 51)       10404       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 204)      0           conv1d_12[0][0]                  \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 30, 204)      816         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 30, 204)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 30, 32)       6528        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 30, 204)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 30, 51)       21216       conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 30, 51)       9792        conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 30, 51)       4896        conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 30, 51)       10404       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 30, 204)      0           conv1d_17[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "                                                                 conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 30, 204)      1224        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 30, 204)      816         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 30, 204)      816         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 30, 204)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 30, 204)      0           batch_normalization_21[0][0]     \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 30, 204)      0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 30, 32)       6528        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 30, 204)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 30, 51)       21216       conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 30, 51)       9792        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 30, 51)       4896        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 30, 51)       10404       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 30, 204)      0           conv1d_23[0][0]                  \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "                                                                 conv1d_25[0][0]                  \n",
      "                                                                 conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 30, 204)      816         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 30, 204)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 30, 32)       6528        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 30, 204)      0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 30, 51)       21216       conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 30, 51)       9792        conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 30, 51)       4896        conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 30, 51)       10404       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 30, 204)      0           conv1d_28[0][0]                  \n",
      "                                                                 conv1d_29[0][0]                  \n",
      "                                                                 conv1d_30[0][0]                  \n",
      "                                                                 conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 30, 204)      816         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 30, 204)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 30, 32)       6528        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 30, 204)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 30, 51)       21216       conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 30, 51)       9792        conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 30, 51)       4896        conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 30, 51)       10404       max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 30, 204)      0           conv1d_33[0][0]                  \n",
      "                                                                 conv1d_34[0][0]                  \n",
      "                                                                 conv1d_35[0][0]                  \n",
      "                                                                 conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 30, 204)      41616       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 30, 204)      816         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 30, 204)      816         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 30, 204)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 30, 204)      0           batch_normalization_25[0][0]     \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 30, 204)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 204)          0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            820         global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 350,770\n",
      "Trainable params: 347,506\n",
      "Non-trainable params: 3,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[2][0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: PhenomeSpectra dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'PhenomeSpectra_'\n",
    "\n",
    "X_train = np.load(os.path.join(DATA, dataset_name + 'X_train.npy'))\n",
    "X_val = np.load(os.path.join(DATA, dataset_name + 'X_val.npy'))\n",
    "X_test = np.load(os.path.join(DATA, dataset_name + 'X_test.npy'))\n",
    "y_train = np.load(os.path.join(DATA, dataset_name + 'y_train.npy'))\n",
    "y_val = np.load(os.path.join(DATA, dataset_name + 'y_val.npy'))\n",
    "y_test = np.load(os.path.join(DATA, dataset_name + 'y_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3315, 217, 11)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: ['B', 'Z', 'OW', 'R', 'AO', 'AH', 'D', 'NG', 'EH', 'UW', 'SH', 'AW', 'T', 'ER', 'DH', 'CH', 'OY', 'L', 'S', 'K', 'JH', 'IH', 'IY', 'G', 'AA', 'TH', 'AE', 'HH', 'F', 'M', 'ZH', 'P', 'AY', 'EY', 'N', 'UH', 'W', 'V', 'Y']\n"
     ]
    }
   ],
   "source": [
    "labels_unique = list(set(y_train))\n",
    "print(\"Unique labels:\", labels_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH',\n",
       "       'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N',\n",
       "       'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH', 'UW', 'V',\n",
       "       'W', 'Y', 'Z', 'ZH'], dtype='<U2')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(labels_unique)\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = lb.fit_transform(y_train)\n",
    "y_val_binary = lb.fit_transform(y_val)\n",
    "y_test_binary = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_train_binary.shape[1]\n",
    "\n",
    "models = modelgen.generate_models(X_train.shape,\n",
    "                                  number_of_classes=num_classes,\n",
    "                                  number_of_models = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tensorflow.python.keras.engine.sequential.Sequential at 0x224c601c278>,\n",
       "  {'learning_rate': 0.02426958952175351,\n",
       "   'regularization_rate': 0.0010503560598147685,\n",
       "   'filters': [76, 96],\n",
       "   'lstm_dims': [83]},\n",
       "  'DeepConvLSTM'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x224c667e4e0>,\n",
       "  {'learning_rate': 0.003037214683656324,\n",
       "   'regularization_rate': 0.0006624372998821501,\n",
       "   'filters': array([89]),\n",
       "   'fc_hidden_nodes': 1798},\n",
       "  'CNN'),\n",
       " (<tensorflow.python.keras.engine.training.Model at 0x224ce1cdda0>,\n",
       "  {'learning_rate': 0.0005725401444849305,\n",
       "   'regularization_rate': 0.004537702362905062,\n",
       "   'network_depth': 4,\n",
       "   'filters_number': 54,\n",
       "   'max_kernel_size': 44},\n",
       "  'InceptionTime'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x224ce2202b0>,\n",
       "  {'learning_rate': 0.0008123143848303106,\n",
       "   'regularization_rate': 0.06357897395522652,\n",
       "   'filters': array([12, 80, 98, 38, 41, 18, 29, 43, 31]),\n",
       "   'fc_hidden_nodes': 1474},\n",
       "  'CNN'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x224cee34e10>,\n",
       "  {'learning_rate': 0.03076393813015092,\n",
       "   'regularization_rate': 0.001222634432726912,\n",
       "   'filters': [51, 97, 20, 94, 25, 53, 29, 62, 15],\n",
       "   'lstm_dims': [54, 18, 90, 69]},\n",
       "  'DeepConvLSTM'),\n",
       " (<tensorflow.python.keras.engine.training.Model at 0x224d4eede48>,\n",
       "  {'learning_rate': 0.000340506453842991,\n",
       "   'regularization_rate': 0.036381992063042504,\n",
       "   'network_depth': 4,\n",
       "   'filters_number': 69,\n",
       "   'max_kernel_size': 58},\n",
       "  'InceptionTime')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 DeepConvLSTM\n",
      "Train on 3314 samples, validate on 1676 samples\n",
      "Epoch 1/50\n",
      "3314/3314 [==============================] - 478s 144ms/step - loss: 4.1691 - acc: 0.0211 - val_loss: 3.8569 - val_acc: 0.0257\n",
      "Epoch 2/50\n",
      "3314/3314 [==============================] - 465s 140ms/step - loss: 3.9269 - acc: 0.0229 - val_loss: 3.8223 - val_acc: 0.0257\n",
      "Epoch 3/50\n",
      "3314/3314 [==============================] - 470s 142ms/step - loss: 3.9412 - acc: 0.0226 - val_loss: 3.7929 - val_acc: 0.0257\n",
      "Epoch 4/50\n",
      "3314/3314 [==============================] - 470s 142ms/step - loss: 3.9272 - acc: 0.0241 - val_loss: 3.8103 - val_acc: 0.0257\n",
      "Epoch 5/50\n",
      "3314/3314 [==============================] - 470s 142ms/step - loss: 3.9296 - acc: 0.0281 - val_loss: 3.7539 - val_acc: 0.0257\n",
      "Epoch 6/50\n",
      "3314/3314 [==============================] - 470s 142ms/step - loss: 3.9316 - acc: 0.0241 - val_loss: 3.7918 - val_acc: 0.0257\n",
      "Epoch 7/50\n",
      "3314/3314 [==============================] - 472s 142ms/step - loss: 3.9348 - acc: 0.0235 - val_loss: 3.8295 - val_acc: 0.0257\n",
      "Epoch 8/50\n",
      "3314/3314 [==============================] - 483s 146ms/step - loss: 3.9252 - acc: 0.0235 - val_loss: 3.7901 - val_acc: 0.0257\n",
      "Epoch 9/50\n",
      "3314/3314 [==============================] - 495s 149ms/step - loss: 3.9422 - acc: 0.0278 - val_loss: 3.8191 - val_acc: 0.0257\n",
      "Epoch 10/50\n",
      "3314/3314 [==============================] - 533s 161ms/step - loss: 3.9233 - acc: 0.0247 - val_loss: 3.8302 - val_acc: 0.0257\n",
      "Epoch 00010: early stopping\n",
      "Training model 1 CNN\n",
      "Train on 3314 samples, validate on 1676 samples\n",
      "Epoch 1/50\n",
      "3314/3314 [==============================] - 157s 47ms/step - loss: 6.2237 - acc: 0.0727 - val_loss: 5.0746 - val_acc: 0.0418\n",
      "Epoch 2/50\n",
      "3314/3314 [==============================] - 139s 42ms/step - loss: 4.0057 - acc: 0.1183 - val_loss: 4.1454 - val_acc: 0.0662\n",
      "Epoch 3/50\n",
      "3314/3314 [==============================] - 141s 43ms/step - loss: 3.8287 - acc: 0.1273 - val_loss: 4.0467 - val_acc: 0.0674\n",
      "Epoch 4/50\n",
      "3314/3314 [==============================] - 126s 38ms/step - loss: 3.7741 - acc: 0.1291 - val_loss: 3.7921 - val_acc: 0.1283\n",
      "Epoch 5/50\n",
      "3314/3314 [==============================] - 116s 35ms/step - loss: 3.7826 - acc: 0.1319 - val_loss: 3.9382 - val_acc: 0.0925\n",
      "Epoch 6/50\n",
      "3314/3314 [==============================] - 119s 36ms/step - loss: 3.8084 - acc: 0.1252 - val_loss: 3.8411 - val_acc: 0.1116\n",
      "Epoch 7/50\n",
      "3314/3314 [==============================] - 115s 35ms/step - loss: 3.7578 - acc: 0.1213 - val_loss: 3.8547 - val_acc: 0.1098\n",
      "Epoch 8/50\n",
      "3314/3314 [==============================] - 114s 35ms/step - loss: 3.7556 - acc: 0.1415 - val_loss: 4.0650 - val_acc: 0.0877\n",
      "Epoch 9/50\n",
      "3314/3314 [==============================] - 116s 35ms/step - loss: 3.7516 - acc: 0.1424 - val_loss: 3.8747 - val_acc: 0.1146\n",
      "Epoch 00009: early stopping\n",
      "Training model 2 InceptionTime\n",
      "Train on 3314 samples, validate on 1676 samples\n",
      "Epoch 1/50\n",
      "3314/3314 [==============================] - 115s 35ms/step - loss: 3.2581 - acc: 0.0935 - val_loss: 4.2195 - val_acc: 0.0597\n",
      "Epoch 2/50\n",
      "3314/3314 [==============================] - 108s 33ms/step - loss: 2.8894 - acc: 0.1497 - val_loss: 3.0885 - val_acc: 0.1390\n",
      "Epoch 3/50\n",
      "3314/3314 [==============================] - 111s 34ms/step - loss: 2.7339 - acc: 0.1928 - val_loss: 3.0197 - val_acc: 0.1366\n",
      "Epoch 4/50\n",
      "3314/3314 [==============================] - 109s 33ms/step - loss: 2.6389 - acc: 0.2040 - val_loss: 3.3314 - val_acc: 0.1384\n",
      "Epoch 5/50\n",
      "3314/3314 [==============================] - 108s 33ms/step - loss: 2.5827 - acc: 0.2176 - val_loss: 3.1581 - val_acc: 0.1462\n",
      "Epoch 6/50\n",
      "3314/3314 [==============================] - 111s 33ms/step - loss: 2.5045 - acc: 0.2390 - val_loss: 2.6864 - val_acc: 0.2166\n",
      "Epoch 7/50\n",
      "3314/3314 [==============================] - 110s 33ms/step - loss: 2.4209 - acc: 0.2544 - val_loss: 3.4911 - val_acc: 0.1080\n",
      "Epoch 8/50\n",
      "3314/3314 [==============================] - 109s 33ms/step - loss: 2.3657 - acc: 0.2743 - val_loss: 3.0256 - val_acc: 0.1689\n",
      "Epoch 9/50\n",
      "3314/3314 [==============================] - 110s 33ms/step - loss: 2.3208 - acc: 0.2942 - val_loss: 2.8552 - val_acc: 0.1975\n",
      "Epoch 10/50\n",
      "3314/3314 [==============================] - 120s 36ms/step - loss: 2.2730 - acc: 0.2957 - val_loss: 2.6194 - val_acc: 0.2124\n",
      "Epoch 11/50\n",
      "3314/3314 [==============================] - 133s 40ms/step - loss: 2.2171 - acc: 0.3168 - val_loss: 2.9395 - val_acc: 0.1963\n",
      "Epoch 12/50\n",
      "3314/3314 [==============================] - 130s 39ms/step - loss: 2.1731 - acc: 0.3386 - val_loss: 2.5596 - val_acc: 0.2428\n",
      "Epoch 13/50\n",
      "3314/3314 [==============================] - 133s 40ms/step - loss: 2.1345 - acc: 0.3518 - val_loss: 2.6422 - val_acc: 0.2369\n",
      "Epoch 14/50\n",
      "3314/3314 [==============================] - 120s 36ms/step - loss: 2.0716 - acc: 0.3549 - val_loss: 2.6281 - val_acc: 0.2297\n",
      "Epoch 15/50\n",
      "3314/3314 [==============================] - 109s 33ms/step - loss: 2.0685 - acc: 0.3573 - val_loss: 2.4270 - val_acc: 0.2745\n",
      "Epoch 16/50\n",
      "3314/3314 [==============================] - 110s 33ms/step - loss: 2.0200 - acc: 0.3654 - val_loss: 2.3880 - val_acc: 0.2828\n",
      "Epoch 17/50\n",
      "3314/3314 [==============================] - 112s 34ms/step - loss: 1.9479 - acc: 0.3877 - val_loss: 2.6026 - val_acc: 0.2375\n",
      "Epoch 18/50\n",
      "3314/3314 [==============================] - 124s 37ms/step - loss: 1.9302 - acc: 0.4001 - val_loss: 2.7364 - val_acc: 0.2434\n",
      "Epoch 19/50\n",
      "3314/3314 [==============================] - 129s 39ms/step - loss: 1.9078 - acc: 0.4083 - val_loss: 2.5189 - val_acc: 0.2613\n",
      "Epoch 20/50\n",
      "3314/3314 [==============================] - 112s 34ms/step - loss: 1.8675 - acc: 0.4188 - val_loss: 2.2632 - val_acc: 0.3091\n",
      "Epoch 21/50\n",
      "3314/3314 [==============================] - 118s 36ms/step - loss: 1.8170 - acc: 0.4342 - val_loss: 2.6599 - val_acc: 0.2452\n",
      "Epoch 22/50\n",
      "3314/3314 [==============================] - 121s 37ms/step - loss: 1.7791 - acc: 0.4415 - val_loss: 2.6107 - val_acc: 0.2643\n",
      "Epoch 23/50\n",
      "3314/3314 [==============================] - 112s 34ms/step - loss: 1.7221 - acc: 0.4547 - val_loss: 2.8030 - val_acc: 0.2345\n",
      "Epoch 24/50\n",
      "3314/3314 [==============================] - 110s 33ms/step - loss: 1.6775 - acc: 0.4653 - val_loss: 3.0809 - val_acc: 0.2303\n",
      "Epoch 25/50\n",
      "3314/3314 [==============================] - 117s 35ms/step - loss: 1.6286 - acc: 0.4774 - val_loss: 2.7327 - val_acc: 0.2375\n",
      "Epoch 00025: early stopping\n",
      "Training model 3 CNN\n",
      "Train on 3314 samples, validate on 1676 samples\n",
      "Epoch 1/50\n",
      "3314/3314 [==============================] - 65s 20ms/step - loss: 27.9156 - acc: 0.0854 - val_loss: 12.7011 - val_acc: 0.0251\n",
      "Epoch 2/50\n",
      "3314/3314 [==============================] - 54s 16ms/step - loss: 8.2528 - acc: 0.1264 - val_loss: 7.0231 - val_acc: 0.0257\n",
      "Epoch 3/50\n",
      "3314/3314 [==============================] - 55s 17ms/step - loss: 5.1946 - acc: 0.1216 - val_loss: 5.7469 - val_acc: 0.0203\n",
      "Epoch 4/50\n",
      "3314/3314 [==============================] - 58s 17ms/step - loss: 4.5105 - acc: 0.1147 - val_loss: 4.9455 - val_acc: 0.0370\n",
      "Epoch 5/50\n",
      "3314/3314 [==============================] - 58s 18ms/step - loss: 4.1932 - acc: 0.1328 - val_loss: 4.2107 - val_acc: 0.0925\n",
      "Epoch 6/50\n",
      "3314/3314 [==============================] - 63s 19ms/step - loss: 4.1390 - acc: 0.1219 - val_loss: 4.1400 - val_acc: 0.0990\n",
      "Epoch 7/50\n",
      "3314/3314 [==============================] - 61s 19ms/step - loss: 4.0174 - acc: 0.1261 - val_loss: 4.2699 - val_acc: 0.1050\n",
      "Epoch 8/50\n",
      "3314/3314 [==============================] - 60s 18ms/step - loss: 4.0230 - acc: 0.1204 - val_loss: 4.2991 - val_acc: 0.0746\n",
      "Epoch 9/50\n",
      "3314/3314 [==============================] - 60s 18ms/step - loss: 4.0227 - acc: 0.1298 - val_loss: 4.3003 - val_acc: 0.0722\n",
      "Epoch 10/50\n",
      "3314/3314 [==============================] - 58s 17ms/step - loss: 3.9820 - acc: 0.1343 - val_loss: 4.5321 - val_acc: 0.0835\n",
      "Epoch 11/50\n",
      "3314/3314 [==============================] - 57s 17ms/step - loss: 4.0311 - acc: 0.1288 - val_loss: 4.0268 - val_acc: 0.1122\n",
      "Epoch 12/50\n",
      "3314/3314 [==============================] - 55s 17ms/step - loss: 3.9748 - acc: 0.1298 - val_loss: 4.0987 - val_acc: 0.1038\n",
      "Epoch 13/50\n",
      "3314/3314 [==============================] - 59s 18ms/step - loss: 3.9736 - acc: 0.1358 - val_loss: 4.1362 - val_acc: 0.1026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "3314/3314 [==============================] - 56s 17ms/step - loss: 4.0399 - acc: 0.1279 - val_loss: 4.2465 - val_acc: 0.0961\n",
      "Epoch 15/50\n",
      "3314/3314 [==============================] - 56s 17ms/step - loss: 3.9125 - acc: 0.1385 - val_loss: 4.4885 - val_acc: 0.0549\n",
      "Epoch 16/50\n",
      "3314/3314 [==============================] - 61s 18ms/step - loss: 3.9174 - acc: 0.1394 - val_loss: 5.6035 - val_acc: 0.0650\n",
      "Epoch 00016: early stopping\n",
      "Training model 4 DeepConvLSTM\n",
      "Train on 3314 samples, validate on 1676 samples\n",
      "Epoch 1/50\n",
      "3314/3314 [==============================] - 733s 221ms/step - loss: 3.8086 - acc: 0.0214 - val_loss: 3.6712 - val_acc: 0.0257\n",
      "Epoch 2/50\n",
      "3314/3314 [==============================] - 732s 221ms/step - loss: 3.6779 - acc: 0.0205 - val_loss: 3.6673 - val_acc: 0.0257\n",
      "Epoch 3/50\n",
      "3314/3314 [==============================] - 729s 220ms/step - loss: 3.6795 - acc: 0.0214 - val_loss: 3.6688 - val_acc: 0.0257\n",
      "Epoch 4/50\n",
      "3314/3314 [==============================] - 761s 230ms/step - loss: 3.6795 - acc: 0.0220 - val_loss: 3.6672 - val_acc: 0.0257\n",
      "Epoch 5/50\n",
      "3314/3314 [==============================] - 717s 216ms/step - loss: 3.6798 - acc: 0.0217 - val_loss: 3.6686 - val_acc: 0.0257\n",
      "Epoch 6/50\n",
      "3314/3314 [==============================] - 724s 219ms/step - loss: 3.6769 - acc: 0.0208 - val_loss: 3.6691 - val_acc: 0.0257\n",
      "Epoch 7/50\n",
      "3314/3314 [==============================] - 807s 244ms/step - loss: 3.6792 - acc: 0.0211 - val_loss: 3.6670 - val_acc: 0.0257\n",
      "Epoch 8/50\n",
      "3314/3314 [==============================] - 736s 222ms/step - loss: 3.6774 - acc: 0.0223 - val_loss: 3.6690 - val_acc: 0.0257\n",
      "Epoch 9/50\n",
      "3314/3314 [==============================] - 676s 204ms/step - loss: 3.6783 - acc: 0.0208 - val_loss: 3.6683 - val_acc: 0.0257\n",
      "Epoch 10/50\n",
      "3314/3314 [==============================] - 679s 205ms/step - loss: 3.6783 - acc: 0.0199 - val_loss: 3.6684 - val_acc: 0.0257\n",
      "Epoch 11/50\n",
      "3314/3314 [==============================] - 690s 208ms/step - loss: 3.6793 - acc: 0.0199 - val_loss: 3.6677 - val_acc: 0.0257\n",
      "Epoch 12/50\n",
      "3314/3314 [==============================] - 723s 218ms/step - loss: 3.6770 - acc: 0.0229 - val_loss: 3.6687 - val_acc: 0.0257\n",
      "Epoch 00012: early stopping\n",
      "Training model 5 InceptionTime\n",
      "Train on 3314 samples, validate on 1676 samples\n",
      "Epoch 1/50\n",
      "3314/3314 [==============================] - 171s 52ms/step - loss: 3.2779 - acc: 0.1008 - val_loss: 3.4611 - val_acc: 0.0865\n",
      "Epoch 2/50\n",
      "3314/3314 [==============================] - 158s 48ms/step - loss: 2.8743 - acc: 0.1635 - val_loss: 3.3613 - val_acc: 0.1158\n",
      "Epoch 3/50\n",
      "3314/3314 [==============================] - 159s 48ms/step - loss: 2.6976 - acc: 0.1859 - val_loss: 3.6865 - val_acc: 0.0800\n",
      "Epoch 4/50\n",
      "3314/3314 [==============================] - 160s 48ms/step - loss: 2.6067 - acc: 0.2043 - val_loss: 3.5535 - val_acc: 0.1175\n",
      "Epoch 5/50\n",
      "3314/3314 [==============================] - 158s 48ms/step - loss: 2.5149 - acc: 0.2384 - val_loss: 2.8926 - val_acc: 0.1695\n",
      "Epoch 6/50\n",
      "3314/3314 [==============================] - 160s 48ms/step - loss: 2.4431 - acc: 0.2559 - val_loss: 3.0885 - val_acc: 0.1605\n",
      "Epoch 7/50\n",
      "3314/3314 [==============================] - 174s 53ms/step - loss: 2.3721 - acc: 0.2785 - val_loss: 2.6535 - val_acc: 0.2106\n",
      "Epoch 8/50\n",
      "3314/3314 [==============================] - 179s 54ms/step - loss: 2.3243 - acc: 0.2803 - val_loss: 2.6007 - val_acc: 0.2369\n",
      "Epoch 9/50\n",
      "3314/3314 [==============================] - 164s 49ms/step - loss: 2.2501 - acc: 0.3014 - val_loss: 2.6473 - val_acc: 0.2214\n",
      "Epoch 10/50\n",
      "3314/3314 [==============================] - 161s 49ms/step - loss: 2.2093 - acc: 0.3150 - val_loss: 2.5192 - val_acc: 0.2554\n",
      "Epoch 11/50\n",
      "3314/3314 [==============================] - 162s 49ms/step - loss: 2.1374 - acc: 0.3419 - val_loss: 2.8086 - val_acc: 0.2190\n",
      "Epoch 12/50\n",
      "3314/3314 [==============================] - 168s 51ms/step - loss: 2.1100 - acc: 0.3449 - val_loss: 2.5251 - val_acc: 0.2464\n",
      "Epoch 13/50\n",
      "3314/3314 [==============================] - 170s 51ms/step - loss: 2.0371 - acc: 0.3715 - val_loss: 2.5237 - val_acc: 0.2500\n",
      "Epoch 14/50\n",
      "3314/3314 [==============================] - 161s 49ms/step - loss: 2.0126 - acc: 0.3660 - val_loss: 3.7254 - val_acc: 0.1539\n",
      "Epoch 15/50\n",
      "3314/3314 [==============================] - 162s 49ms/step - loss: 1.9816 - acc: 0.3835 - val_loss: 2.4913 - val_acc: 0.2757\n",
      "Epoch 16/50\n",
      "3314/3314 [==============================] - 172s 52ms/step - loss: 1.9377 - acc: 0.3911 - val_loss: 2.7429 - val_acc: 0.2232\n",
      "Epoch 17/50\n",
      "3314/3314 [==============================] - 165s 50ms/step - loss: 1.8679 - acc: 0.4185 - val_loss: 2.4801 - val_acc: 0.2745\n",
      "Epoch 18/50\n",
      "3314/3314 [==============================] - 160s 48ms/step - loss: 1.8297 - acc: 0.4363 - val_loss: 2.4983 - val_acc: 0.2607\n",
      "Epoch 19/50\n",
      "3314/3314 [==============================] - 163s 49ms/step - loss: 1.7784 - acc: 0.4484 - val_loss: 2.6184 - val_acc: 0.2733\n",
      "Epoch 20/50\n",
      "3314/3314 [==============================] - 163s 49ms/step - loss: 1.7368 - acc: 0.4538 - val_loss: 2.6361 - val_acc: 0.2751\n",
      "Epoch 21/50\n",
      "3314/3314 [==============================] - 168s 51ms/step - loss: 1.7109 - acc: 0.4704 - val_loss: 2.8511 - val_acc: 0.2428\n",
      "Epoch 22/50\n",
      "3314/3314 [==============================] - 155s 47ms/step - loss: 1.6335 - acc: 0.4843 - val_loss: 2.6409 - val_acc: 0.2703\n",
      "Epoch 00022: early stopping\n",
      "Details of the training process were stored in  C:\\OneDrive - Netherlands eScience Center\\Project_mcfly\\trained_models\\modelcomparison_PhenomeSpectra.json\n"
     ]
    }
   ],
   "source": [
    "resultpath = 'C:\\\\OneDrive - Netherlands eScience Center\\\\Project_mcfly\\\\trained_models'\n",
    "outputfile = os.path.join(resultpath, 'modelcomparison_PhenomeSpectra.json')\n",
    "histories, val_accuracies, val_losses = find_architecture.train_models_on_samples(X_train, y_train_binary,\n",
    "                                                                           X_val, y_val_binary,\n",
    "                                                                           models,nr_epochs=50,\n",
    "                                                                           subset_size=-1,\n",
    "                                                                           verbose=True,\n",
    "                                                                           outputfile=outputfile)\n",
    "print('Details of the training process were stored in ',outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.02426958952175351, 'regula...</td>\n",
       "      <td>0.024744</td>\n",
       "      <td>3.923343</td>\n",
       "      <td>0.025656</td>\n",
       "      <td>3.830216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.003037214683656324, 'regul...</td>\n",
       "      <td>0.142426</td>\n",
       "      <td>3.751630</td>\n",
       "      <td>0.114558</td>\n",
       "      <td>3.874683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.0005725401444849305, 'regu...</td>\n",
       "      <td>0.477369</td>\n",
       "      <td>1.628646</td>\n",
       "      <td>0.237470</td>\n",
       "      <td>2.732671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.0008123143848303106, 'regu...</td>\n",
       "      <td>0.139409</td>\n",
       "      <td>3.917401</td>\n",
       "      <td>0.065036</td>\n",
       "      <td>5.603480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.03076393813015092, 'regula...</td>\n",
       "      <td>0.022933</td>\n",
       "      <td>3.676959</td>\n",
       "      <td>0.025656</td>\n",
       "      <td>3.668724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 0.000340506453842991, 'regul...</td>\n",
       "      <td>0.484309</td>\n",
       "      <td>1.633545</td>\n",
       "      <td>0.270286</td>\n",
       "      <td>2.640933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  train_acc  train_loss  \\\n",
       "0  {'learning_rate': 0.02426958952175351, 'regula...   0.024744    3.923343   \n",
       "1  {'learning_rate': 0.003037214683656324, 'regul...   0.142426    3.751630   \n",
       "2  {'learning_rate': 0.0005725401444849305, 'regu...   0.477369    1.628646   \n",
       "3  {'learning_rate': 0.0008123143848303106, 'regu...   0.139409    3.917401   \n",
       "4  {'learning_rate': 0.03076393813015092, 'regula...   0.022933    3.676959   \n",
       "5  {'learning_rate': 0.000340506453842991, 'regul...   0.484309    1.633545   \n",
       "\n",
       "    val_acc  val_loss  \n",
       "0  0.025656  3.830216  \n",
       "1  0.114558  3.874683  \n",
       "2  0.237470  2.732671  \n",
       "3  0.065036  5.603480  \n",
       "4  0.025656  3.668724  \n",
       "5  0.270286  2.640933  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelcomparisons_phenome = pd.DataFrame({'model':[str(params) for model, params, model_types in models],\n",
    "                       'train_acc': [history.history['acc'][-1] for history in histories],\n",
    "                       'train_loss': [history.history['loss'][-1] for history in histories],\n",
    "                       'val_acc': [history.history['val_acc'][-1] for history in histories],\n",
    "                       'val_loss': [history.history['val_loss'][-1] for history in histories]\n",
    "                       })\n",
    "modelcomparisons_phenome.to_csv(os.path.join(resultpath, 'modelcomparison_PhenomeSpectra.csv'))\n",
    "\n",
    "modelcomparisons_phenome"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
